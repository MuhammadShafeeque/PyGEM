{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The Python Glacier Evolution Model (PyGEM) is an open-source glacier evolution model coded in Python that is designed to model the transient evolution of glaciers on regional and global scales. Each glacier is modeled independently using a given time step and elevation bins. The model computes the climatic mass balance (i.e., snow accumulation minus melt plus refreezing) for each elevation bin and each monthly time step. Glacier geometry is updated annually. The model outputs a variety of data including monthly mass balance and its components (accumulation, melt, refreezing, frontal ablation, glacier runoff),  and annual volume, volume below sea level, and area.\n",
    "\n",
    "PyGEM has a modular framework that allows different schemes to be used for model calibration or model physics (e.g., ablation, accumulation, refreezing, glacier dynamics). The most recent version of PyGEM, published in <em>Science</em> [(Rounce et al. 2023)](https://www.science.org/doi/10.1126/science.abo1324), has been made compatible with the Open Global Glacier Model [(OGGM)](https://oggm.org/) to both leverage the pre-processing tools (e.g., digital elevation models, glacier characteristics) and their advances with respect to modeling glacier dynamics and ice thickness inversions.\n",
    "\n",
    "```{note}\n",
    "Looking for a quick overview? Check out the [Model Structure and Workflow](model_structure_and_workflow_target).\n",
    "<br>Want to read some studies?  Check out our [publications](publications_target)!\n",
    "<br>Want to see what PyGEM can do? Check out this [presentation about PyGEM's latest developments](https://www.youtube.com/watch?v=gaGzEIjIJlc)!\n",
    "```\n",
    "\n",
    "## Citing PyGEM\n",
    "The most recent version of PyGEM was published in <em>[Science](https://www.science.org/doi/10.1126/science.abo1324)</em>. Therefore, if using PyGEM, please cite:\n",
    "<br><br>Rounce, D.R., Hock, R., Maussion, F., Hugonnet, R., Kochtitzky, W., Huss, M., Berthier, E., Brinkerhoff, D., Compagno, L., Copland, L., Farinotti, D., Menounos, B., and McNabb, R.W. (2023). “Global glacier change in the 21st century: Every increase in temperature matters”, <em>Science</em>, 379(6627), pp. 78-83, doi:10.1126/science.abo1324.\n",
    "\n",
    "```{figure} _static/science_cover.jpg\n",
    "---\n",
    "width: 50%\n",
    "---\n",
    "```\n",
    "\n",
    "## Contact us\n",
    "The PyGEM community is growing! As the community grows, we hope individuals will continue to support one another. For now, if you have questions, we recommend emailing David Rounce (drounce@cmu.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inputs\n",
    "The minimum data required to run the model is a glacier inventory, glacier characteristics (ice thickness, hypsometry, etc.), climate data, and mass balance data for calibration ([Table 1](model_input_table_target)). The model uses glacier outlines provided by the [Randolph Glacier Inventory](https://www.glims.org/RGI/) (RGI Consortium 2017; RGI 6.0 contains 215,547 glaciers globally). For debris-covered glaciers, spatially distributed sub-debris melt enhancement factors can be used to account for the enhanced or suppressed melting depending on the debris thickness [(Rounce et al. 2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311). OGGM is used to select a digital elevation model (DEM) for each glacier and bin the data according to the glacier central flowlines. OGGM can also be used to estimate each glacier’s initial ice thickness or use existing ice thickness estimates available from the [OGGM Shop](https://docs.oggm.org/en/stable/shop.html).\n",
    "\n",
    "For present-day (2000-2019) model runs, PyGEM currently uses monthly near-surface air temperature and precipitation data from ERA5 [(Hersbach et al. 2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3803). Air temperature lapse rates are estimated using monthly air temperature data from various pressure levels. A second option is available to derive lapse rates from the neighboring pixels; however, this is for glaciers near the coast and therefore is not recommended. Additionally, the monthly temperature standard deviation is required if incorporating sub-monthly temperature variability in ablation (see below). Note that historical runs (e.g., 1980-2000) are challenging due to the lack of glacier inventories in the past; hence, one can assume the glacier area is constant or run the model in reverse (e.g., 1999, 1998, … , 1980). However, due to nonlinearities associated with the glacier dynamics running if the model is run in reverse and then forward, the glacier areas will be different in 2000 than the initial dataset; hence, caution must be used and the results should be evaluated carefully.\n",
    "\n",
    "For future (e.g., 2000-2100) model runs, PyGEM currently uses an ensemble of General Circulation Models (GCMs) and Shared Socioeconomic Pathways (SSPs) from the Coupled Model Intercomparison Project Phase 6 (CMIP6). The model can also be run using Representative Concentration Pathways (RCPs) associated with CMIP5. Future simulations are adjusted using additive factors for air temperature and multiplicative factors for precipitation to remove any bias between the GCMs and ERA5 data over the calibration period (2000-2019). Additional bias corrections options will be available in the future.\n",
    "\n",
    "(model_input_table_target)=\n",
    "Table 1. Data requirements for PyGEM. Optional datasets are shown in italics.\n",
    "\n",
    "| Component | Dataset | References |\n",
    "| :--- | :--- | :--- |\n",
    "| [Glacier data](input_glacier_inventory_target) | Randolph Glacier Inventory Version 6.0 | [RGI Consortium (2017)](https://www.glims.org/RGI/) |\n",
    "| [Climate data](climate_data_target) | 1: ERA5 monthly air temperature, monthly precipitation, and orography <br><em>2: ERA5 monthly lapse rates (from pressure level data) and monthly air temperature variance (from ERA5 hourly data)</em> <br>3: CMIP5 or CMIP6 monthly air temperature, monthly precipitation, and orography | [Hersbach et al. (2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3803) |\n",
    "| [Mass balance data](input_mb_data_target) | 1: Geodetic glacier-wide mass balance (m w.e. yr$^{-1}$) <br>2: Glaciological glacier-wide mass balance (m w.e. yr$^{-1}$) <br><em>3: All other data need to be programmed</em> | [Hugonnet et al. (2021)](https://www.nature.com/articles/s41586-021-03436-z) <br> [WGMS (2021)](https://wgms.ch/data_databaseversions/) |\n",
    "| [Debris data](input_debris_data_target) (optional) | <em>Sub-debris melt factors </em> | [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) |\n",
    "| [Frontal ablation data](input_fa_data_target) (optional) | <em>1: Frontal ablation per glacier (Gt yr-1) <br>Used to calibrate marine-terminating glaciers </em> | [Osmanoglu et al. (2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014)](https://tc.copernicus.org/articles/8/1807/2014/); [Minowa et al. (2021)](https://www.sciencedirect.com/science/article/pii/S0012821X21000704); [Kochtitzky et al. (2022)](https://www.nature.com/articles/s41467-022-33231-x) |\n",
    "| [Ice thickness data](input_thickness_data_target) (optional) </em>| <em>Spatially distributed ice thickness data <br>Used to calibrate creep parameter to match volume of existing ice thickness dataset </em>| [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3)|\n",
    "\n",
    "```{note}\n",
    "A sample of all relevant data to perform a test run of the model is provided [here](https://drive.google.com/file/d/159zS-oGWLHG9nzkFdsf6Uh4-w9lJSt8H/view?usp=sharing). The different sources of data required to run the model are provided below including instructions on where to download the data. We recommend reviewing the sample data to address any questions you may have concerning the structure of the datasets.\n",
    "```\n",
    "\n",
    "(input_glacier_inventory_target)=\n",
    "## Glacier Inventory\n",
    "The current model structure of defining the glaciers uses the Randolph Glacier Inventory version 6.0 (RGI Consortium 2017), but theoretically any glacier inventory that uses the same format and provides the same information (e.g., RGIId, Area, Terminus Type, Median elevation) would be applicable. The glacier inventory is formatted as a .csv file. The latest version of the RGI can be downloaded [here](https://www.glims.org/RGI/).\n",
    "\n",
    "## Glacier Hypsometry\n",
    "The mass balance model can be run with information concerning glacier hypsometry; however, to account for glacier dynamics, the model requires information concerning the glacier's ice thickness as well. These data are available through the Glacier Model Intercomparison Project (GlacierMIP) (Marzeion et al. 2020) or can be derived workflows from OGGM ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)). We recommend using pre-processed glacier direcotry from the [OGGM Shop](https://docs.oggm.org/en/stable/shop.html).\n",
    "\n",
    "There are several options for pre-processed data from OGGM and we recommend you read the documentation in [OGGM Shop](https://docs.oggm.org/en/stable/shop.html). The model is currently configured to use Level 2 data with a border value of 40 m using elevation bands.  OGGM will automatically download the glacier directories based on the link you specify in the input file; however, if you would like to download them in advance (e.g., if your supercomputing environment does not allow you to access the internet within the script), then you may use the following as an example of how you can download these data to your local computer from OGGM’s server:\n",
    "\n",
    "```\n",
    "wget -r --no-parent https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.4/L1-L2_files/elev_bands/RGI62/b_240/L2/ \n",
    "```\n",
    "\n",
    "(climate_data_target)=\n",
    "## Climate Data (Reference)\n",
    "PyGEM requires a reference climate dataset, i.e., climate data that covers the calibration period. These data are provided as netcdf (.nc) files. The model is currently configured to use monthly data.\n",
    "\n",
    "For reference climate data (e.g., 2000-2020), PyGEM uses ERA5, which superseded ERA-Interim due to its higher resolution and other strengths. The following data is required with optional data noted accordingly:\n",
    "* Air temperature\n",
    "* Precipitation (total, i.e., liquid and solid)\n",
    "* Orography (geopotential)\n",
    "* Air temperature lapse rates\n",
    "* Air temperature daily standard deviation <em>(optional)</em>\n",
    "\n",
    "These data can be downloaded, or are derived from downloaded data, from the [Copernicus Climate Change Service (C3S) Climate Data Store](https://cds.climate.copernicus.eu/#!/search?text=ERA5&type=dataset). Instructions for downloading these climate data may be found [here](https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5). Specific detail on each dataset is provided below.\n",
    "\n",
    "### Monthly temperature\n",
    "Monthly near-surface (2 m) air temperature can be downloaded directly. This is used to calculate the positive degree days for melt, annual air temperature for refreezing, and to differentiate liquid and solid precipitation.\n",
    "\n",
    "### Monthly precipitation\n",
    "Monthly precipitation can be downloaded directly. This is used to calculate accumulation and runoff and is the total precipitation over the time period, which is currently monthly.\n",
    "\n",
    "### Orography\n",
    "Orography can be downloaded directly. This is used to account for elevation differences between the climate data pixel and the glaciers.\n",
    "\n",
    "### Lapse rates\n",
    "Monthly air temperature lapse rates are derived from monthly air temperature at each pressure level from 300 to 1000 hPa ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). The air temperature at various pressure levels can be downloaded and then processed using the 'createlapserates' option from **preprocess_ecmwf_data.py** in the **PyGEM-Scripts** respoitory. These lapse rates are used to adjust the air temperature for differences in elevations between the climate pixel and the glacier as well as for various elevation bins on the glacier.\n",
    "\n",
    "### Monthly temperature standard deviation\n",
    "Monthly air temperature standard deviation is an optional product, which is only required if you plan to account for the monthly temperature variations within ablation like was done in [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). These monthly data are derived from hourly near-surface air temperature. Hourly near-surface air temperature can be downloaded and processed using the 'createtempstd' option from **preprocess_ecmwf_data.py** in the **PyGEM-Scripts** respoitory. Note that the hourly data is quite large and therefore this step will take considerable time to download and process the data.\n",
    "\n",
    "## Climate Data (Future)\n",
    "The projected climate data has been developed using general circulation models (GCMs) from the Coupled Model Intercomparison Project Phase 5 (CMIP5), which uses Representative Concentration Pathways (RCPs) and CMIP Phase 6 (CMIP6), which uses Shared Socioeconomic Pathways (SSPs). While the use of RCPs may be of interest for comparison with previous studies, we recommend using SSPs moving forward.\n",
    "\n",
    "The climate data required is:\n",
    "* Air temperature\n",
    "* Precipitation\n",
    "* Orography\n",
    "\n",
    "These data are provided as netcdf (.nc) files and can be downloaded from [OGGM’s server](https://cluster.klima.uni-bremen.de/~oggm/). \n",
    "\n",
    "To account for differences between the reference and future climate data, bias adjustments are made to the future temperature and precipitation data. These are described in the [Section on Bias Corrections].\n",
    "\n",
    "(input_mb_data_target)=\n",
    "## Model Calibration and Validation Data\n",
    "The choice of calibration and validation data is entirely up to the modeler. However, PyGEM is currently configured to be calibrated with glacier-wide geodetic mass balance data and validated using glacier-wide glaciological data.\n",
    "\n",
    "### Calibration data\n",
    "Model parameters need to be calibrated and results should be validated using some form of mass balance (glaciological, geodetic, or gravimetric), glacier runoff, snowline, or equilibrium line altitude data ([Table 1](model_input_table_target)). Additional calibration data is required to account for frontal ablation associated with marine-terminating glaciers. We envision the model continuously incorporating new large-scale systematic datasets as they become available. \n",
    "\n",
    "The model was originally developed to integrate large-scale systematic glacier-wide mass balance data from 2000-2018 in High Mountain Asia [(Shean et al. 2020)](https://www.frontiersin.org/articles/10.3389/feart.2019.00363/full) and now uses a global dataset from 2000-2019 [(Hugonnet et al. 2021)](https://www.nature.com/articles/s41586-021-03436-z). The default frontal ablation data is currently from various datasets spanning 2000 to 2020 from the Northern Hemisphere [(Kochtitzky et al. 2022)](https://www.nature.com/articles/s41467-022-33231-x), South America [(Minowa et al. 2021)](https://www.sciencedirect.com/science/article/pii/S0012821X21000704), and Antarctica [(Osmanoglu et al. 2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014)](https://tc.copernicus.org/articles/8/1807/2014/). For model validation, annual and seasonal glaciological glacier-wide mass balance data from 1979 to 2019 have been used [(WGMS 2021)](https://wgms.ch/data_databaseversions/).\n",
    "\n",
    "The current file structure for both the geodetic and frontal ablation data are .csv files. It's important to enter all the relevant information within the “Calibration Datasets” section of **pygem_input.py**. The key information is the glacier's RGIId, mass balance in m water equivalent (w.e.) yr$^{-1}$, mass balance error/uncertainty, initial time, end time, and area of the glacier. Processing of these data for each glacier is done in the \"shop\" directory under the **mbdata.py** script. We recommend reviewing the sample mass balance data for additional information on file structure.\n",
    "\n",
    "### Validation data\n",
    "The model is currently developed to use glacier-wide annual and seasonal mass balance data for validation from the World Glacier Monitoring Service ([WGMS](https://wgms.ch/data_databaseversions/)).\n",
    "\n",
    "In addition to its use for model validation, the WGMS winter mass balance data is also used to constrain the initial calibration that is used to estimate the prior distributions for the Markov Chain Monte Carlo simulations. This processing is performed in **‘run_preprocessing_wgms_mbdata.py’** using the ‘-estimate_kp’ option.\n",
    "\n",
    "(input_debris_data_target)=\n",
    "## Debris Thickness Data\n",
    "For debris-covered glaciers, spatially distributed sub-debris melt enhancement factors are required. These files are provided by [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) as .tif files. There are currently scripts in the “shop” directory that process the .tif files and aggregate them to elevation bins to be consistent with the glacier directory structure of OGGM. If using a different dataset, this pre-processing would need to be added.\n",
    "\n",
    "(input_fa_data_target)=\n",
    "## Frontal Ablation Data\n",
    "The default frontal ablation data is currently from various datasets spanning 2000 to 2020 from the Northern Hemisphere ([Kochtitzky et al. 2022](https://www.nature.com/articles/s41467-022-33231-x)), South America ([Minowa et al. 2021](https://www.sciencedirect.com/science/article/pii/S0012821X21000704)), and Antarctic/Subantarctic ([Osmanoglu et al. 2013](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0); [2014](https://tc.copernicus.org/articles/8/1807/2014/)).\n",
    "\n",
    "(input_thickness_data_target)=\n",
    "## Ice Thickness Data\n",
    "The default ice thickness data is currently the \"consensus\" ice thickness estiamtes from [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3). These estimates are used to calibrate the ice viscocity parameter such that the modeled ice thickness estimates roughly match the \"consensus\" ice thickness estimates at a regional scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(model_structure_and_workflow_target)=\n",
    "# Model Structure and Workflow\n",
    "The model is written in Python. The model is currently available as two repositories on github:\n",
    "\n",
    "1. **PyGEM** ([https://github.com/drounce/PyGEM](https://github.com/drounce/PyGEM)) contains the main model code.  This repository can now be installed in your environment with PyPI ([https://pypi.org/project/pygem/](https://pypi.org/project/pygem/)) using \"pip install pygem\".\n",
    "\n",
    "2. **PyGEM-scripts** ([https://github.com/drounce/PyGEM-scripts](https://github.com/drounce/PyGEM-scripts)) contains general scripts used to run the model (e.g., run_calibration.py, run_simulation.py) as well as the post-processing, analysis scripts (e.g., analyze_simulations.py). To use these files and run the model one must clone the github repository onto your local machine.\n",
    "\n",
    "All input parameters are specified in the pygem_input.py file, which needs to be adjusted according to the specific datasets and model options of each user. The input file is well documented inline and [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ) are produced to support trial runs.\n",
    "\n",
    "(directory_structure_target)=\n",
    "## Directory structure\n",
    "Currently, the model does not have a “required” set of directories. For simplicity with github, we highly recommend keeping the forked version of the code in its own directory. Furthermore, since many of the datasets that will be used for regional and global model runs are of considerable size, we encourage users to develop their own organized file structure. The code has been developed to automatically set up all file paths using relative paths from the PyGEM-Scripts directory, which is where the code is run from the command line. For example, a directory with the following subdirectories is recommended (see [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ)):\n",
    "\n",
    "* climate_data\n",
    "  - This directory contains the reference and future climate data\n",
    "* debris_data (optional)\n",
    "  - This directory contains data concerning the debris thickness and sub-debris melt enhancement factors. \n",
    "* DEMs\n",
    "  - This directory contains the geodetic mass balance data derived from DEM differencing that is used for calibration.\n",
    "* IceThickness_Farinotti (optional)\n",
    "  - This directory includes the consensus ice thickness estimates (Farinotti et al. 2019). The directory is optional unless you want to match the consensus ice thickness estimates.\n",
    "* oggm_gdirs\n",
    "  - This directory contains the glacier directories downloaded from OGGM. This directory will be automatically generated by the pre-processing steps from OGGM.\n",
    "* Output\n",
    "  - This directory contains all model output\n",
    "* PyGEM-scripts\n",
    "  - This directory contains scripts to run the model and process output\n",
    "* RGI\n",
    "  - This directory contains the RGI glacier information\n",
    "* WGMS (optional)\n",
    "  - This directory contains the WGMS mass balance data for validation. The directory is optional in case you prefer to validate your model with different data.\n",
    "  \n",
    "```{warning}\n",
    "If you use a different file structure and do not update the file paths in the **pygem_input.py**, you will get an error and PyGEM will not run!\n",
    "```\n",
    "\n",
    "(model_workflow_target)=\n",
    "## Model Workflow\n",
    "The model code itself is heavily commented with the hope that the code is easy to follow and develop further. After downloading the required input files and setting up the directory structure (or modifying the **pygem_input.py** with your preferred directory structure) you are ready to run the code! Generally speaking, the workflow includes:\n",
    "* [Pre-process data](preprocessing_target) <em>(optional if including more data)</em>\n",
    "* [Set up input file](input_workflow_target)\n",
    "* [Calibrate frontal ablation parameter](workflow_cal_frontalablation_target) <em>(optional if accounting for frontal ablation with marine-terimating glaciers)</em>\n",
    "* [Calibrate mass balance parameters](workflow_cal_prms_target)\n",
    "* [Calibrate ice viscocity parameter](workflow_cal_glena_target)\n",
    "* [Run model simulation](workflow_sim_target)\n",
    "* [Post-process output](workflow_post_target)\n",
    "* [Analyze output](workflow_analyze_target)\n",
    "\n",
    "(preprocessing_target)=\n",
    "### Pre-processing \n",
    "We rely heavily on [OGGM's pre-processing modules](https://docs.oggm.org/en/stable/shop.html), which are state-of-the-art. For most people, these glacier directories will be sufficient to get started. However, there are times when we work with different datasets and need to do our own pre-processing. For example, the following script corrects the geodetic mass balance from [Hugonnet et al. (2021)](https://www.nature.com/articles/s41586-021-03436-z) to account for the mass lost below the water level due to frontal ablation from [Kochtitzky et al. (2022)](https://www.nature.com/articles/s41467-022-33231-x).\n",
    "```\n",
    "python run_preprocessing_wgms_mbdata.py -mb_data_removeFA=1\n",
    "```\n",
    "(input_workflow_target)=\n",
    "### Set up input file\n",
    "**pygem_input.py** is the input file were the user can specify the glaciers/regions to model; model physics, calibration, and simulation options; relative filepaths for relevant datasets; etc.\n",
    "\n",
    "(workflow_cal_frontalablation_target)=\n",
    "### Calibrate frontal ablation parameter\n",
    "**Optional Step** If you want to account for frontal ablation associated with marine-terminating glaciers, then the frontal ablation parameter needs to be calibrated. This is done using **run_calibration_frontalablation.py** with the following steps:\n",
    "<br>Merge the frontal ablation data together into a single directory:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_data = True)\n",
    "```\n",
    "Calibrate the frontal ablation parameter for each marine-terminating glacier:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_ind_calving_k = True)\n",
    "```\n",
    "Merge all the frontal ablation parameters into a single file:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_calving_k = True)\n",
    "```\n",
    "Update the climatic-basal mass balance data by removing the frontal ablation from the total mass change:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_update_mb_data = True)\n",
    "```\n",
    "```{note}\n",
    "The run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. \n",
    "```\n",
    "(workflow_cal_prms_target)=\n",
    "### Calibrate mass balance model parameters\n",
    "The model parameters (degree-day factor of snow, precipitation factor, and temperature bias) must be calibrated. This is done using **run_calibration.py**. Several options exist (see [Model Calibration](calibration_target) for specific details), but generally speaking the <em>option_calibration</em> will be specified in **pygem_input.py** and then the following is run:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "```{note}\n",
    "The Markov Chain Monte Carlo (MCMC) methods require several steps and additional python packages (i.e., PyMC2 and its dependencies. See [MCMC methods](MCMC_target) for the specific workflow.\n",
    "```\n",
    "\n",
    "(workflow_cal_glena_target)=\n",
    "### Calibrate ice viscosity model parameter\n",
    "The ice viscocity (glen_a) model parameter is calibrated such that the ice volume estimated using the calibrated mass balance gradients are consistent with the consensus ice volume estimates ([Farinotti et al. 2019]((https://www.nature.com/articles/s41561-019-0300-3))) for each RGI region. This is done by running the following:\n",
    "```\n",
    "python run_calibration_icethickness_consensus.py\n",
    "```\n",
    "Considerations:\n",
    "* This code is currently not set up to run automatically as it has the regions hard-coded within the script. The reason for this hard-coding is to be able to run the script, while other scripts are running too (e.g., calibration). This should be changed in the future to facilitate automation though.\n",
    "* In  pygem_input.py, you need to set option_dynamics=‘OGGM’. Otherwise, you’ll get an assertion error telling you to do so, since you won’t be able to record the output otherwise.\n",
    "* While the code runs at the RGI Order 1 region scale, it will only calibrate for the glaciers that have calibration data and run successfully.\n",
    "* pygem_input.py has a parameter ‘icethickness_cal_frac_byarea’ that is used to set the fraction of glaciers by area to include in this calibration. The default is 0.9 (i.e., the largest 90% of glaciers by area). This is to reduce computational expense, since the smallest 10% of glaciers by area contribute very little to the regional volume.\n",
    "\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../Output/calibration/‘glena_region.csv’ \n",
    "\n",
    "(workflow_sim_target)=\n",
    "### Run model simulation\n",
    "If no GCMs are specified in the command line, the default will be to run a model simulation with the reference data (e.g., ERA5). We currently recommend that <br><em>**historical simulations**</em> be performed without evolving the glacier geometry; thus, <em>option_dynamics = None</em> in **pygem_input.py** and the <em>ref_startyear</em> and <em>ref_endyear</em> are used to set the length of the simulation. The simulation can then be run using the following:\n",
    "```\n",
    "python run_simulation.py\n",
    "```\n",
    "<em>**Future simulations**</em> require specifying a GCM and scenario, which is passed to the script through the argument parser. For example, the following will run a simulation for CESM2 SSP2-4.5:\n",
    "```\n",
    "python run_simulation.py -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "```{note}\n",
    "For future simulations, at a minimum the user should specify the dynamical option (<em>option_dynamics</em>), start year (<em>gcm_startyear</em>), end year (<em>gcm_endyear</em>), bias correction option (<em>option_bias_adjustment</em>).\n",
    "```\n",
    "\n",
    "(workflow_post_target)=\n",
    "### Post-process output\n",
    "There are currently several scripts available to process the datasets (e.g., merge them into regional files, create multi-GCM means and standard deviations for each SSP). While these scripts are well documented in line, they still need to be cleaned up for more widespread use.  An example:\n",
    "```\n",
    "python process_simulation.py\n",
    "```\n",
    "(workflow_analyze_target)=\n",
    "### Analyze output\n",
    "All users will analyze PyGEM output in different ways; however, we aim to provide some general scripts to produce publication-quality figures of mass, area, and runoff change such as those within the analysis_Science_figs.py. Figure options and pathways will be hard-coded within these scripts for the present moment. An example:\n",
    "```\n",
    "python analysis_Science_figs.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass Balance Models\n",
    "\n",
    "PyGEM computes the climatic mass balance for each elevation bin and timestep, estimates frontal ablation for marine-terminating glaciers at the end of each year (if this process is included), and updates the glacier geometry annually. The convention below follows [Cogley et al. (2011)](https://wgms.ch/downloads/Cogley_etal_2011.pdf). The total glacier-wide mass balance ($\\Delta M$) is thus estimated as:\n",
    "\n",
    "```{math}\n",
    "\\Delta M = B_{clim} + A_{f}/S\n",
    "```\n",
    "\n",
    "where $B_{clim}$ is the climatic mass balance in specific units, i.e. mass change per unit area (m w.e.), $A_{f}$ is frontal ablation, and $S$ is the glacier area. The basal mass balance is assumed to be zero.\n",
    "\n",
    "The climatic mass balance for each elevation bin ($b_{clim}$) is computed according to:\n",
    "```{math}\n",
    "b_{clim} = a + c + R\n",
    "```\n",
    "\n",
    "where $a$ is the ablation, $c$ is accumulation, and $R$ is refreezing (all in units of m w.e.). Mass loss is negative and mass gain is positive. The glacier-wide specific climatic mass balance ($B_{clim}$) is thus calculated by:\n",
    "```{math}\n",
    "\\sum_{i=1}^{nbins} b_{clim,i}\n",
    "```\n",
    "\n",
    "The model offers alternative methods for calculating the mass balance components and accounting for glacier geometry changes (i.e., representing glacier dynamics). These vary in level of complexity and computational expense. The current options for each component are described below:\n",
    "\n",
    "```{toctree}\n",
    "---\n",
    "caption: Mass Balance Components:\n",
    "maxdepth: 2\n",
    "---\n",
    "\n",
    "mb_ablation\n",
    "mb_accumulation\n",
    "mb_refreezing\n",
    "mb_frontalablation\n",
    "```\n",
    "\n",
    "## Summary of model parameters\n",
    "Below is a summary of some of the key mass balance model parameters, their symbols, units, and the values used in PyGEM. Note that some parameters are calculated, others are calibrated, and others may be specified by the user in the input file.\n",
    "\n",
    "| Parameter | Symbol | Unit | Value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Ablation | $a$ | m w.e. | calculated |\n",
    "| Accumulation | $c$ | m w.e. | calculated |\n",
    "| Refreeze | $R$ | m w.e. | calculated |\n",
    "| Frontal ablation | $A_{f}$ | m w.e. | calculated |\n",
    "| Degree-day factor of snow | $f_{snow}$ | mm w.e. d$^{-1}$ K$^{-1}$ | calibrated |\n",
    "| Degree-day factor of ice | $f_{ice}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $f_{snow}$/0.7 <br>(user-specified) |\n",
    "| Degree-day factor of firn | $f_{firn}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $\\frac{f_{snow}+f_{ice}}{2}$ |\n",
    "| Degree-day factor of debris | $f_{debris}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $E_{d} \\cdot f_{ice}$ |\n",
    "| Sub-debris melt enhancement factor | $E_{d}$ | - | 1 if no debris; <br> otherwise from [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) |\n",
    "| Temperature bias correction | $T_{bias}$ | K | calibrated |\n",
    "| Threshold temperature (rain/snow) | $T_{snow}$ | $^{\\circ}$C | 1 <br> (user-specified) |\n",
    "| Precipitation correction factor | $k_{p}$ | - | calibrated |\n",
    "| Precipitation gradient | $d_{prec}$ | m$^{-1}$ | 0.0001 <br> (user-specified) |\n",
    "| Frontal ablation scaling parameter | $k$ | yr$^{-1}$ | calibrated |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation\n",
    "There are currently two model options for ablation. Both model options use a degree-day model ($f$). \n",
    "\n",
    "### Option 1: monthly temperatures\n",
    "The first calculates ablation ($a$) using the mean monthly temperature:\n",
    "$$a=f_{snow/ice/firn/debris} \\cdot T_{m}^{+} \\cdot n$$\n",
    "\n",
    "where $f$ is the degree-day factor of snow, ice, firn, or debris (m w.e. d-1 °C$^{-1}$), $T_{m}^{+}$ is the positive monthly mean temperature (°C), and $n$ is the number of days per month. \n",
    "\n",
    "### Option 2: monthly temperatures with daily variance\n",
    "The second option incorporates the daily variance associated with the temperature for each month according to [Huss and Hock (2015)]((https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)):\n",
    "$$a=f_{snow/ice/firn/debris} \\cdot \\sum_{i=1}^{ndays} T_{d,i}^{+} $$\n",
    "\n",
    "where $T_{d}$ is the daily positive mean air temperature and is estimated by superimposing random variability from the standard deviation of the daily temperature for each month.\n",
    "\n",
    "The degree-day factors for snow, ice, firn, and debris depend on the surface type option that is chosen by the user (see Section 5). The values of $f$ for these various surface types are assumed to be related to one another to reduce the number of model parameters. The default ratio of the $f_{snow}$ to the $f_{ice}$ is 0.7, and $f_{firn}$ is assumed to be the mean of the $f_{snow}$ and $f_{ice}$; however, the user may change these values in the input file if desired. The values for $f_{debris}$ are equal to $f_{ice}$ multiplied by the mean sub-debris melt enhancement factor [(Rounce et al. 2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) for the given elevation bin.\n",
    "\n",
    "### Temperature at elevation bins\n",
    "Temperature for each elevation bin ($T_{bin}$) is determined by selecting the temperature from the gridded climate data ($T_{gcm}$) based on the nearest neighbor, which is then downscaled to the elevation bins on the glacier according to:\n",
    "$$T_{bin} = T_{gcm} + lr_{gcm} \\cdot (z_{ref} - z_{gcm}) + lr_{glac} \\cdot (z_{bin} - z_{ref}) + T_{bias}$$\n",
    "\n",
    "where $lr_{gcm}$ and $lr_{glac}$ are lapse rates (°C m-1) associated with downscaling the climate data to the glacier and then over the glacier elevation bins, respectively; $z_{ref}$, $z_{gcm}$, and $z_{bin}$ are the elevations from the glacier’s reference point (median or mean elevation), the climate data, and the elevation bin, respectively; and $T_{bias}$ is the temperature bias. The temperature bias is one of three model parameters that is calibrated and serves to account for any biases resulting from the use of coarse climate data that is unable to capture local topographic variations. By default, the $lr_{gcm}$ and $lr_{glac}$ are assumed to be equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulation\n",
    "Accumulation ($c$) is calculated for each elevation bin as a function of the precipitation ($P_{bin}$), air temperature ($T_{bin}$), and the snow temperature threshold ($T_{snow}$).  There are two options for estimating accumulation based on how to classify precipitation as liquid or solid. \n",
    "\n",
    "### Option 1: Threshold +/- 1$^{\\circ}$C\n",
    "The first (default) option is to estimate the ratio of liquid and solid precipitation based on the air temperature:\n",
    "$$c = \\delta \\cdot P_{bin}$$\n",
    "\n",
    "where $\\delta=1$; if $T_{bin} \\leq T_{snow}-1$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\delta=0$; if $T_{bin} \\geq T_{snow}+1$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\delta=0.5-(T_{bin}-T_{snow})/2$; if $T_{snow}-1 < T_{bin} < T_{snow}+1$\n",
    "\n",
    "<br>where $P_{bin}$ is the monthly precipitation and $\\delta$ is the fraction of solid precipitation each month. $T_{snow}$ typically ranges from 0 – 2 $^{\\circ}$C ([Radić and Hock, 2011](https://www.nature.com/articles/ngeo1052); [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)) and is typically assumed to be 1$^{\\circ}$C.  \n",
    "\n",
    "### Option 2: Single threshold\n",
    "The alternative option is to classify precipitation as snow or rain based on a single threshold.\n",
    "\n",
    "### Precipitation at elevation bins\n",
    "Precipitation at each elevation bin of the glacier ($P_{bin}$) is determined by selecting the precipitation from the gridded climate data ($P_{gcm}$) based on the nearest neighbor, which is then downscaled to the elevation bins on the glacier:\n",
    "$$P_{bin} = P_{GCM} \\cdot k_{p} \\cdot (1 + d_{prec} \\cdot (z_{bin} - z_{ref}))$$\n",
    "<br>where $k_{p}$ is the precipitation factor and $d_{prec}$ is the precipitation gradient. The precipitation factor is a model parameter that is used to adjust from the climate data to the glacier, which could be caused by local topographic effects due to differences in elevation, rain shadow effects, etc. The precipitation gradient is another model parameter, which is used to redistribute the precipitation along the glacier and can be thought of as a precipitation lapse rate. Typical values for the precipitation gradient vary from 0.01 – 0.025% m$^{-1}$([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) who cited [WGMS, 2012](https://wgms.ch/products_fog/)). The default assumes a precipitation gradient of 0.01% m$^{-1}$ to reduce the number of model parameters.\n",
    "\n",
    "Additionally, for glaciers with high relief (> 1000 m), the precipitation in the uppermost 25% of the glacier’s elevation is reduced using an exponential function ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)):\n",
    "$$P_{bin,exp} = P_{bin} \\cdot exp(\\frac{z_{bin} - z_{75\\%}}{z_{max} - z_{75\\%}}) $$\n",
    "where $P_{bin,exp}$ is the adjusted precipitation, and $z_{max}$ and $z_{75\\%}$ are the elevation of the glacier maximum and the glacier’s 75th percentile elevation, respectively. The adjusted precipitation cannot be lower than 87.5% of the maximum precipitation on the glacier. This adjustment accounts for the reduced air moisture and increased wind erosion at higher elevations ([Benn and Lehmkuhl, 2000](https://risweb.st-andrews.ac.uk/portal/en/researchoutput/mass-balance-and-equilibriumline-altitudes-of-glaciers-in-highmountain-environments(080f17fc-33dd-4805-bc97-a5aaa018a457)/export.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refreezing\n",
    "There are two model options for computing refreezing.  The default option estimates refreezing based on the mean annual air temperature ([Woodward et al. 1997](https://www.cambridge.org/core/journals/annals-of-glaciology/article/influence-of-superimposedice-formation-on-the-sensitivity-of-glacier-mass-balance-to-climate-change/84DFA08E9CC8F28BE0729F1EBF4DA4E1)), while the alternative is based on heat conduction ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)).\n",
    "\n",
    "### Option 1: Mean annual air temperature\n",
    "For the default option, refreezing (R) is calculated for each elevation bin as a function of its weighted annual mean air temperature (Ta) following [Woodward et al. (1997)](https://www.cambridge.org/core/journals/annals-of-glaciology/article/influence-of-superimposedice-formation-on-the-sensitivity-of-glacier-mass-balance-to-climate-change/84DFA08E9CC8F28BE0729F1EBF4DA4E1)):\n",
    "$$R = -0.0069 \\cdot T_{a} + 0.000096$$\n",
    "The weighted annual mean accounts for the number of days in each month. Refreezing cannot be negative. The model assumes that refreezing occurs in the snowpack as opposed to being superimposed ice, so in the ablation zone the refreezing cannot exceed the snow depth. Since this option estimates annual refreezing, the equation above provides the maximum amount of potential refreezing. Each year, the potential refreezing is reset in October as this is the transition season from predominantly summer melt to winter accumulation. Therefore, it is possible that accumulated snow may melt and refreeze diurnally. The model replicates this physical behavior by first determining the amount of snow that has melted in that month. If the refreezing potential is greater than zero, the model assumes the snow melts and refreezes in the snow pack. Refreezing cannot exceed the amount of snow melt in any given month. The amount of refreezing is then subtracted from the potential refreezing until the potential refreezing is fully depleted or reset. Once the snow and refreezing completely melts, the model can melt the underlying ice/firn/snow.  This model is used as the default because it is computationally cheap compared to the alternative.\n",
    "\n",
    "### Option 2: Heat conduction\n",
    "The alternative option is to estimate refreezing using modeled snow and firn temperatures based on heat conduction as described by [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). This option is significantly more computationally expensive. The code for this section was translated from the IDL code used in [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full), which potentially has an error in the heat conduction equation where the temperature in each layer is divided by a factor of 2 that Lilian Schuster identified is not physically-derived (as of 2021 - this error has not been fixed). This option should thus be used with caution until further developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontal Ablation\n",
    "For marine-terminating glaciers, frontal ablation is modeled using a frontal ablation parameterization coupled to the ice dynamical model (i.e., the glacier dynamics parameterization). Given the coupling to the dynamical model, frontal ablation is accounted for on an annual timestep and the code for the frontal ablation parameterization is located with the dynamical model. OGGM provides a nice overview of the frontal ablation parameterization in one of their advanced tutorials:\n",
    "\n",
    "https://oggm.org/tutorials/stable/notebooks/kcalving_parameterization.html\n",
    "\n",
    "The same parameterization is included for mass redistribution curves in PyGEM.\n",
    "\n",
    "Frontal ablation ($A_{f}$) computes the mass that is removed at the glacier front when the bedrock is below sea level using an empirical formula following [Oerlemans and Nick (2005)](https://www.cambridge.org/core/journals/annals-of-glaciology/article/minimal-model-of-a-tidewater-glacier/C6B72F547D8C44CDAAAD337E1F2FC97F):\n",
    "$$A_{f} = k \\cdot d \\cdot H_{f} \\cdot w$$\n",
    "where $k$ is the frontal ablation scaling parameter (yr$^{-1}$), $d$ is the water depth at the calving front (m), $H_{f}$ is the ice thickness at the calving front, and $w$ is the glacier width at the calving front. Over the next century, many marine-terminating glaciers are projected to retreat onto land based on present-day frontal ablation rates ([Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324)); hence, the maximum frontal ablation rate is constrained by the mass of ice where the bed elevation of the bin is located below sea level. The user is also able to specify the water level (default is 0), which supports the application of the parameterization to lake-terminating glaciers in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier Dynamics\n",
    "Glacier dynamics in large-scale glacier evolution models typically rely on geometry changes like volume-area-length scaling (e.g., [Radić and Hock, 2011](https://www.nature.com/articles/ngeo1052)), mass redistribution using empirical equations (e.g., [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)), or simplified glacier dynamics (e.g., [Maussion et al., 2019](https://gmd.copernicus.org/articles/12/909/2019/)). [Zekollari et al. (2022)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021RG000754) provide a comprehensive review of ice dynamics for mountain glaciers. These methods all allow the glacier to evolve over time in response to the total glacier-wide mass balance. The benefit of volume-area-length scaling and mass redistribution is they are computationally inexpensive compared to simplified glacier dynamics methods. The two options available in PyGEM are OGGM’s flowline model using the shallow ice approximation ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)) and mass redistribution curves ([Rounce et al. 2020](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)).\n",
    "\n",
    "## Option 1: OGGM flowline model using shallow-ice approximation\n",
    "PyGEM has been developed to be compatible with OGGM thereby enabling the use of their ice dynamics flowline model ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)). The model uses a shallow ice approximation with a depth-integrated flowline model to explicitly compute the flux of ice along the glacier centerline. Model details are fully documented in OGGM’s manual found [here](https://docs.oggm.org/en/latest/ice-dynamics.html).\n",
    "\n",
    "(mass_redistribution_curves_target)=\n",
    "## Option 2: Mass redistribution curves\n",
    "The mass redistribution curves in PyGEM follow those developed by [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) based on [Huss et al. (2010)](https://hess.copernicus.org/articles/14/815/2010/hess-14-815-2010.html) but explicitly solve for area and ice thickness changes simultaneously to conserve mass. The approach is only applied to glaciers that have at least three elevation bins. Each year the glacier-wide mass balance is computed (see Mass Balance Section) and the mass is redistributed over the glacier using empirical equations that set the normalized surface elevation change ($\\Delta h$) as a function of the glacier’s elevation bins:\n",
    "$$\\Delta h = (h_{n} + a_{HH2015})^{\\gamma} + b_{HH2015} \\cdot (h_{n} + a_{HH2015}) + c_{HH2015} $$\n",
    "where $h_{n}$ is the normalized elevation according to $\\frac{z_{max} - z_{bin}}{z_{max} - z_{min}}$ and $a_{HH2015)$, $b_{HH2015)$, $c_{HH2015)$, and $\\gamma$ are all calibrated coefficients based on 34 glaciers in the Swiss Alps. These coefficients vary depending on the size of the glacier ([Huss et al., 2010]((https://hess.copernicus.org/articles/14/815/2010/hess-14-815-2010.html))). In order to ensure that mass is conserved, i.e., the integration of the elevation change and glacier area (A) of each bin over all the elevation bins ($nbins$) is equal to the glacier-wide volume change ($\\Delta V$), an ice thickness scaling factor ($f_{s,HH2015}$) must be computed:\n",
    "$$f_{s,HH2015} = \\frac{\\Delta V}{\\sum_{i=0}^{nbins} A_{i} \\cdot \\Delta h_{i}} $$\n",
    "The volume change in each elevation bin ($\\Delta V_{bin}$) is computed as:\n",
    "$$\\Delta V_{bin} = f_{s,HH2015} \\cdot \\Delta h_{bin} \\cdot A_{bin} $$\n",
    "Depending on the bed shape (parabolic, triangular or rectangular) of the glacier, the resulting area, ice thickness ($H$), and width ($W$) can be solved for explicitly based on mass conservation and the use of similar shapes:\n",
    "$$H_{bin,t+1} \\cdot A_{bin,t+1} = H_{bin,t} \\cdot A_{bin,t} + \\Delta V_{bin} $$\n",
    "$$\\frac{H_{bin,t+1}}{H_{bin,t}} \\alpha \\frac{A_{bin,t+1}}{A_bin,t} $$\n",
    "This is a marked improvement over previous studies that have not explicitly solved for the area and ice thickness changes simultaneously, which can lead to mass loss or gain that is then corrected ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)).\n",
    "\n",
    "### Glacier retreat\n",
    "Glacier retreat occurs when the volume change in an elevation bin ($\\Delta V_{bin}$) causes the ice thickness for the next time step to be less than zero. In this case, the ice thickness is set to zero and the remaining volume change is redistributed over the entire glacier according to the mass redistribution described above. \n",
    "\n",
    "### Glacier advance\n",
    "Glacier advance occurs when the ice thickness change exceeds the ice thickness advance threshold (default: 5 m; [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). When this occurs, the ice thickness change is set to 5 m, the area and width of the bin are calculated accordingly, and the excess volume is recorded. The model then calculates the average area and thickness associated with the bins located in the glacier’s terminus, which is defined by the terminus percentage (default: 20%). However, this calculation excludes the bin actually located at the terminus because prior to adding a new elevation bin, the model checks that the bin located at the terminus is “full”. Specifically, the area and ice thickness of the lowermost bin are compared to the terminus’ average and if the area and ice thickness is less than the average, then the lowermost bin is first filled until it reaches the terminus average. This ensures that the lowermost bin is “full” and prevents adding new bins to a glacier that may only have a relatively small excess volume in consecutive years. In other words, if this criterion did not exist, then it would be possible to add new bins over multiple years that had small areas, which would appear as though the glacier was moving down a steep slope.\n",
    "\n",
    "If there is still excess volume remaining after filling the lowermost bin to the terminus average, then a new bin is added below the terminus. The ice thickness in this new bin is set to be equal to the terminus average and the area is computed based on the excess volume. If the area of this bin would be greater than the average area of the terminus, this indicates that an additional bin needs to be added. However, prior to adding an additional bin the excess volume is redistributed over the glacier again. This allows the glacier’s area and thickness to increase and prevents the glacier from having a thin layer of ice that advances down-valley without thickening.\n",
    "\n",
    "There are two exceptions for when a glacier is not allowed to advance to a particular bin. The first exception is if the added bin would be below sea-level, in which case the remaining excess volume is redistributed over the entire glacier. The second exception is if the bin is over a known discontinuous section of the glacier, which is determined based on the initial glacier area. For example, it is possible, albeit unlikely, that a glacier could retreat over a discontinuous section of a glacier and then advance in the future. This discontinuous area is assumed to be a steep vertical drop, hence why a glacier currently does not exist, so a glacier is not allowed to form there in the future. The glacier instead skips over this discontinuous bin and a new bin is added below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier Runoff\n",
    "Following [Huss and Hock (2018)](https://www.nature.com/articles/s41558-017-0049-x), glacier runoff ($Q$) is defined as all water that leaves the initial glacierized area, which includes rain ($P_{liquid}$), ablation ($a$), and refreezing ($R$) as follows:\n",
    "\n",
    "```{math}\n",
    "Q = P_{liquid} + a - R\n",
    "```\n",
    "\n",
    "In the case of glacier retreat, rain, snow melt, and refreezing are computed for the non-glaciated portion of the initial glacier area and this runoff is referred to as “off-glacier” runoff. No other processes, e.g., evapotranspiration or groundwater recharge, are accounted for in these deglaciated areas. \n",
    "\n",
    "```{warning}\n",
    "In the case of glacier advance, runoff is computed over the current year’s glacier area, which may exceed the initial glacierized area. Given that most glaciers are retreating, the increase in glacier runoff due to the additional glacier area is considered to be negligible.\n",
    "```\n",
    "\n",
    "Excess meltwater is defined as the runoff caused by glacier mass loss that the glacier does not regain over the duration of the entire simulated period (**Figure 1**). For example, a glacier that melts completely contributes its entire mass as excess meltwater, while a glacier in equilibrium produces no excess meltwater. Since interannual glacier mass change is highly variable, i.e., a glacier can lose, gain, and then lose mass again, excess meltwater is computed retroactively as the last time that the glacier mass is lost.\n",
    "\n",
    "```{figure} _static/excess_meltwater_diagram.png\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "```\n",
    "\n",
    "**Figure 1.** Diagram exemplifying how excess meltwater (blue dashed line) is calculated retroactively based on annual glacier mass balance (black line) over time. Cumulative (top subplot) and annual (bottom subplot) mass balance and excess meltwater are shown. Years refer to mass-balance years and values of cumulative mass balances and excess meltwater refer to the end of each mass-balance year. The total excess meltwater is equivalent to the total mass loss over the entire period, and therefore is not equal to the absolute sum of all annual negative mass balances if positive mass balances have occurred in the period. Excess meltwater is distributed retroactively over all mass-balance years that are negative and where the lost mass is not regained in the future. For example, annual mass balances in year 6, 7 and 9 are negative, but all mass loss lost between year 6 and 10 is regained by the end of year 10; thus, excess meltwater is zero in years 6 to 10 despite negative annual mass balances. Excess meltwater for any year with negative mass balance cannot exceed the annual net mass loss of that year. The figure is copied from [Rounce et al. (2020)](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Conditions and Surface Type\n",
    "Initial glacier area is based on the RGI and assumed to represent the year 2000.  The initial surface type is based on the glacier’s median elevation, with the higher elevation being classified as firn and the lower classified as ice (or debris-covered). The surface type evolves based on the five-year running average of the glacier bin’s annual climatic mass balance ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). If the five running average is positive, then the surface is classified as firn, while if it is negative, the surface is classified as ice. The surface type is classified as snow when snow accumulates on the surface.\n",
    "\n",
    "During the ice thickness inversion, which is done using OGGM ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)), the glacier is assumed to be in steady state. As a result, at the start of the simulation, there is typically a dynamical adjustment as the ice thickness is redistributed in response to the climatic mass balance forcing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(calibration_target)=\n",
    "# Model Calibration\n",
    "Several calibration options exist, which vary with respect to complexity and computational expense. These include the relatively straightforward approach of [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full), which is referred to as ‘HH2015’ to more complex Bayesian approaches from [Rounce et al. (2023)](https://www.science.org/doi/10.1126/science.abo1324) (‘MCMC’) ([Table 1](cal_options_table_target). At present, the options all use geodetic glacier-wide mass balance data for each glacier in units of meters of water equivalent (m w.e.) per year ([Hugonnet et al. 2021]((https://www.nature.com/articles/s41586-021-03436-z)). The calibration is done assuming the glacier area remains constant to avoid mass balance-ice thickness circularity issues.\n",
    "\n",
    "(cal_options_table_target)=\n",
    "\n",
    "| Calibration option | Overview | Reference |\n",
    "| :--- | :--- | :--- |\n",
    "| ['HH2015'](HH2015_target) | Finds single set of parameters.<br>Varies in order: $f_{snow}$, $k_{p}$, $T_{bias}$ | [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) |\n",
    "| ['HH2015mod'](HH2015mod_target) | Finds single set of parameters.<br>Varies in order: $k_{p}$, $T_{bias}$ | [Rounce et al. 2020](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432) |\n",
    "| ['emulator'](emulator_target) | Creates emulator for ['MCMC'](MCMC_target).<br>Finds single set of parameters with emulator following ['HH2015mod'](HH2015mod_target) | [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324) |\n",
    "| ['MCMC'](MCMC_target) | Finds multiple sets of parameters using Bayesian inference with [emulator](emulator_target).<br> Varies $f_{snow}$, $k_{p}$, $T_{bias}$ | [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324) |\n",
    "| ['MCMC_fullsim'](MCMC_target) | Finds multiple sets of parameters using Bayesian inference with full model simulations.<br> Varies $f_{snow}$, $k_{p}$, $T_{bias}$ | [Rounce et al. 2020](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432) |\n",
    "| [Future options](cal_custom_target) | Stay tuned for new options coming in 2023/2024! | | \n",
    "\n",
    "The output of each calibration is a .pkl file that holds a dictionary of the calibration options and the subsequent model parameters.  Thus, the .pkl file will store several calibration options.  Each calibration option is a key to the dictionary. The model parameters are also stored in a dictionary (i.e., a dictionary within a dictionary) with each model parameter being a key to the dictionary that provides access to a list of values for that specific model parameter. The following shows an example of how to print a list of the precipitation factors ($k_{p}$) for the calibration option specified in the input file:\n",
    "\n",
    "```\n",
    "with open(modelprms_fullfn, 'rb') as f:\n",
    "    modelprms_dict = pickle.load(f)\n",
    "print(modelprms_dict[pygem_prms.option_calibration][‘kp’])\n",
    "```\n",
    "\n",
    "The calibration options are each discussed below.  We recommend using the MCMC calibration option (Rounce et al. [2020a](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432), [2020b](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full), [2023](https://www.science.org/doi/10.1126/science.abo1324)) as this enables the user to quantify the uncertainty associated with the model parameters in the simulations; however, it is very computationally expensive. The methods from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) provide a computationally cheap alternative. \n",
    "\n",
    "```{note}\n",
    "Running these options is performed using **run_calibration.py** (see [Model Workflow](workflow_cal_prms_target)). Additionally, there are two other calibration scripts to calibrate the [ice viscocity model parameter](workflow_cal_glena_target) using the **run_calibration_icethickness_consensus.py** and the [frontal ablation parameter](calibration_frontalablation_target) for marine-terminating glaciers using the **run_calibration_frontalablation.py**.\n",
    "```\n",
    "\n",
    "(HH2015_target)=\n",
    "## HH2015\n",
    "The calibration option **‘HH2015’** follows the calibration steps from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). Specifically, the precipitation factor is initially adjusted between 0.8-2.0. If agreement between the observed and modeled mass balance is not reached, then the degree-day factor of snow is adjusted between 1.75-4.5 mm d$^{-1}$ K$^{-1}$. Note that the ratio of the degree-day factor of ice to snow is set to 2, so both parameters are adjusted simultaneously. Lastly, if agreement is still not achieved, then the temperature bias is adjusted.\n",
    "\n",
    "(HH2015mod_target)=\n",
    "## HH2015mod\n",
    "The calibration option **‘HH2015mod’** is a modification of the calibration steps from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) that are used to generate the prior distributions for the MCMC methods [(Rounce et al. 2020a)](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432)\n",
    ". Since the MCMC methods used degree-day factors of snow based on previous studies, only the precipitation factor and temperature bias are calibrated. The precipitation factor varies from 0.5-3 and if agreement is not reached between the observed and modeled mass balance, then the temperature bias is varied. Note the limits on the precipitation factor are estimated based on a rough estimate of the precipitation factors needed for the modeled winter mass balance of reference glacier to match the observations.\n",
    "\n",
    "However, if you plan to use the MCMC methods, you are suggested to use the **‘emulator’** calibration option described below, which follows the same steps, but creates an emulator to run the mass balance simulations for each potential parameter set to reduce the computational expense.\n",
    "\n",
    "(emulator_target)=\n",
    "## Emulator applying HH2015mod\n",
    "The calibration option **‘emulator’** creates an independent emulator for each glacier that is derived by performing 100 present-day simulations based on randomly sampled model parameter sets and then fitting a Gaussian Process to these parameter-response pairs. This model replaces the mass balance model within the MCMC sampler (see Bayesian inference using MCMC below), which tests showed reduces the computational expense by two orders of magnitude. In the event that a single set of model parameters is desired, the emulator is also used to derive a set of model parameters following the same steps as ‘HH2015mod’.\n",
    "\n",
    "```{note}\n",
    "The ‘emulator’ calibration option will generate both the .pkl file of the model parmaters as well as the model simulations and emulators for each glacier stored in a subdirectory named 'emulator'.\n",
    "```\n",
    "\n",
    "```{note}\n",
    "The ‘emulator’ calibration option needs to be run before the ‘MCMC’ option.\n",
    "```\n",
    "\n",
    "(MCMC_target)=\n",
    "## Bayesian inference using Markov Chain Monte Carlo methods\n",
    "The calibration option **‘MCMC’** is the recommended option. Details of the methods are provided by Rounce et al. ([2020a](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432), [2023](https://www.science.org/doi/10.1126/science.abo1324)). In short, Bayesian inference is performed using Markov Chain Monte Carlo (MCMC) methods, which requires a mass balance observation (including the uncertainty represented by a standard deviation) and prior distributions. In an ideal world, we would have enough data to use broad prior distributions (e.g., uniform distributions), but unfortunately the model is overparameterized meaning there are an infinite number of parameter sets that give us a perfect fit. We therefore must use an empirical Bayes approach by which we use a simple optimization scheme (the **‘HH2015mod’** calibration option) to generate our prior distributions at the regional scale, and then use these prior distributions for the Bayesian inference. The prior distribution for the degree-day factor is based on previous data ([Braithwaite 2008](https://www.cambridge.org/core/journals/journal-of-glaciology/article/temperature-and-precipitation-climate-at-the-equilibriumline-altitude-of-glaciers-expressed-by-the-degreeday-factor-for-melting-snow/6C2362F61B7DE7F153247A039736D54C)), while the temperature bias and precipitation factor are derived using a simple optimization scheme based on each RGI Order 2 subregion. The temperature bias assumes a normal distribution and the precipitation factor assumes a gamma distribution to ensure positivity. Glacier-wide winter mass balance data ([WGMS 2020](https://wgms.ch/data_databaseversions/)) are used to determine a reasonable upper-level constraint for the precipitation factor for the simple optimization scheme.\n",
    "\n",
    "The MCMC methods thus require several steps. First, set the <em>option_calibration = ‘emulator’</em> in **pygem_input.py**. This creates an emulator that helps speed up the simulations within the MCMC methods and helps generate an initial calibration to generate the regional priors. Run this initial calibration:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "The regional priors are then determined by running the following:\n",
    "```\n",
    "python run_mcmc_prior.py\n",
    "```\n",
    "This will output a .csv file that has the distributions for the temperature bias and precipitation factors for each Order 2 RGI subregion. This file is located in the calibration subdirectory within the Output directory.\n",
    "\n",
    "Once the regional priors are set, the MCMC methods can be performed.  Change the <em>option_calibration = ‘MCMC’</em> in **pygem_input.py**, then run the following:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "In order to reduce the file size, the parameter sets are thinned by a factor of 10. This is reasonable given the correlation between subsequent parameter sets during the Markov Chain, but can be adjusted if thinning is not desired (change value to 1 in the input file).\n",
    "\n",
    "```{note}\n",
    "**'MCMC_fullsim'** is another calibration option that runs full model simulations within the MCMC methods instead of using the emulator. It is computationally very expensive but allows one to assess the emulators impact on the MCMC methods.\n",
    "```\n",
    "\n",
    "(cal_custom_target)=\n",
    "## Customized Calibration Routines\n",
    "As new observations become available, we envision the calibration routines will need to change to leverage these observations. The only real limitation in developing a calibration routine is that the dictionary stored as a .pkl file needs to be consistent such that the calibration option is consistent with the run_simulation.py script.\n",
    "\n",
    "(calibration_frontalablation_target)=\n",
    "## Frontal Ablation Parameter for Marine-terminating Glaciers\n",
    "Marine-terminating glaciers have an additional frontal ablation parameter that is calibrated at the glacier-scale to match frontal ablation data [(Osmanoglu et al. 2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014;](https://tc.copernicus.org/articles/8/1807/2014/) [Minowa et al. 2021;](https://www.sciencedirect.com/science/article/pii/S0012821X21000704) [Kochtitzky et al. 2022](https://www.nature.com/articles/s41467-022-33231-x)). Marine-terminating glaciers require a special procedure for calibration to avoid circularity issues. The initial ice thickness is estimated using the mass balance parameters assuming the glacier is land-terminating and a forward simulation from 2000-2020 estimates the frontal ablation. If a dynamic instability error occurs (8% of glaciers for [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324)), the glacier dynamics model uses [mass redistribution curves](mass_redistribution_curves_target) instead. For quality control, we combined the frontal ablation and geodetic mass balance observations to estimate climatic mass balances. For some glaciers, the resulting climatic mass balances are unrealistic due to errors in the RGI outlines and/or poor glacier thickness and velocity data used in frontal ablation calculations. For these glaciers, we assume frontal ablation is overestimated and reduce the frontal ablation to ensure the climatic mass balance is within three standard deviations of the regional mean from the geodetic mass balance data. The Antarctic and Subantarctic have the sparsest frontal ablation data, so the region’s median frontal ablation parameter and corresponding standard deviation is used for glaciers without data.\n",
    "\n",
    "The frontal ablation calibration is a hard-coded script that requires several steps. First, you need to change the region within the run_calibration_frontalablation.py script. Then merge the frontal ablation data together into a single directory:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_data = True)\n",
    "```\n",
    "Followed by calibrating the frontal ablation parameter for each marine-terminating glacier:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_ind_calving_k = True)\n",
    "```\n",
    "Then merge all the frontal ablation parameters into a single file:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_calving_k = True)\n",
    "```\n",
    "Lastly, update the climatic-basal mass balance data by removing the frontal ablation from the total mass change:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_update_mb_data = True)\n",
    "```\n",
    "```{note}\n",
    "The run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. \n",
    "```\n",
    "\n",
    "## Ice Viscocity Parameter\n",
    "The ice viscocity parameter will affect the ice thickness inversion and dynamical evolution of the glacier. The ice viscocity parameter is currently calibrated such that the volume of ice at the regional scale is consistent with the regional ice volumes from [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "While PyGEM has a number of strengths, we also want to be transparent of several limitations that the current version has:\n",
    "* **Monthly timestep**: while we plan to add the option to use daily data in the future, the model is currently only set up for monthly timesteps.\n",
    "* **ERA5 climate data**: we currently use ERA5 data as our reference data and this is the only dataset that PyGEM currently supports. We are aware of recent studies that have shown reanalysis precipitation data have issues compared to other data (Alexander et al. 2020) and may consider alternative precipitation data in the future.  The class_climate.py script can be modified to incorporate others.\n",
    "* **Geodetic mass balance data**: while we envision adding options to incorporate other datasets (e.g., multiple mass balance datasets, mass balance gradients, snowline altitudes) for model calibration, the current framework is set up for a single glacier-wide mass balance observation for each glacier. Note that the geodetic mass balance data requires the time period to be specific with each observation; however, the time period does not have to be the same for each glacier.\n",
    "* **Glacier-specific workflow**: the model requires mass balance data for each glacier for model calibration. We hope to incorporate regional data as well in the future.\n",
    "* **Off-glacier snow accumulation**: when the glacier retreats, the model continues to compute accumulation, melt, and refreeze of snow over the deglaciated area. Glacier retreat may create off-glacier areas at high altitudes. At high altitudes, it’s possible for the temperature to be negative year-round and thereby cause off-glacier snow to accumulate unrealistically over time. Potential solutions could include removing the snow each year assuming that it sublimates, developing an avalanche parameterization to add the snow onto the glacier, or an alternative we have not yet considered. It is good to be aware of this since snow at this elevation will not contribute to off-glacier runoff since it doesn’t melt.\n",
    "* **Runoff for advancing glaciers**: when the glacier advances, the model continues to compute the runoff over the entire glacier area, which may exceed the initial glacierized area.\n",
    "* **Initialization at 2000**: the RGI is used to initialize the glacier areas. While the RGI targets all glacier extents to be from 2000, this may significantly vary depending on the source of the data. We assume the glacier extents represent 2000 and do not correct for these issues.\n",
    "* **Mass balance-ice thickness circularity issues**: circular issues exist regarding the derivation of the mass balance gradient and the ice thickness, i.e., a mass balance gradient is needed to estimate the ice thickness and yet the ice thickness will determine how the glacier evolves. To avoid these circularity issues, we calibrate the model assuming the glacier area is constant.\n",
    "* **Frontal ablation for marine-terminating glaciers**: currently the frontal ablation parameterization is only set up for marine-terminating glaciers based on the terminus type specific by the RGI. Theoretically, the same framework could be applied to lake-terminating glaciers, but to our knowledge, datasets for calibration are not yet available and the formation of lakes is not yet included in the model.\n",
    "* **PyMC2**: the Markov Chain Monte Carlo (MCMC) methods are currently implemented using PyMC2. The developers of PyMC2 have created a new version PyMC3; however, the new version requires non-trivial changes to PyGEM’s mass balance code and therefore we continue to use PyMC2 at present. Building a conda environment that satisfies all the dependencies including PyMC2 can be challenging, and likely will become increasingly challenging in the future. We hope to develop a new calibration framework in 2023/2024 that is easier to install.\n",
    "* **Continual development**: PyGEM is constantly evolving. We will do our best to keep documents updated, but it's always helpful to let us know if you're using PyGEM so we can ensure you are aware of the latest and/or upcoming changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(publications_target)=\n",
    "# Select Publications\n",
    "* Rounce, D.R., Hock, R., Maussion, F., Hugonnet, R., Kochtitzky, W., Huss, M., Berthier, E., Brinkerhoff, D., Compagno, L., Copland, L., Farinotti, D., Menounos, B., and McNabb, R.W. (2023). “[Global glacier change in the 21st century: Every increase in temperature matters](https://www.science.org/doi/10.1126/science.abo1324)”, Science, 379(6627), pp. 78-83, doi:10.1126/science.abo1324\n",
    "* Rounce, D.R., Hock, R., and Shean, D.E. (2020). “[Glacier mass change in High Mountain Asia through 2100 using the open-source Python Glacier Evolution Model (PyGEM)](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)”, Frontiers in Earth Science, 7(331), pp. 1-20, doi:10.3389/feart.2019.00331\n",
    "* Rounce, D.R., Khurana, T., Short, M.B., Hock, R., Shean, D.E., and Brinkherhoff, D.J. (2020). “[Quantifying parameter uncertainty in a large-scale glacier evolution model using Bayesian inference – Application to High Mountain Asia](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432)”, Journal of Glaciology, 66(256), pp. 175-187, doi:10.1017/jog.2019.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQS\n",
    "- Add them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Hints\n",
    "- Using argument parser\n",
    "- How to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(install_pygem_target)=\n",
    "# Installing PyGEM\n",
    "The model is setup in [two repositories](model_structure_and_workflow_target) that are installed via PyPI and github as described below.\n",
    "\n",
    "## Setup Conda Environment\n",
    "A conda environment is a directory that contains a specific collection of installed packages. The use of environments reduces issues caused by package dependencies. The model is designed to be compatible with OGGM. We therefore get started by following the [installation instructions from OGGM](https://docs.oggm.org/en/stable/installing-oggm.html).\n",
    "\n",
    "Once your conda environment is setup for OGGM, add the core of PyGEM using pip.\n",
    "\n",
    "```\n",
    "pip install pygem\n",
    "```\n",
    "\n",
    "This will provide you with a conda environment that has the basic functionality to run simple calibration options (e.g., 'HH2015', 'HH2015mod') and simulations. If you want to use the emulators and Bayesian inference, the advanced environment is required. \n",
    "\n",
    "### Advanced environment: PyMC2 and PyTorch\n",
    "If you want to use the emulators or Bayesian inference associated with PyGEM additional packages are required.\n",
    "\n",
    "```{warning}\n",
    "The current dependencies are fairly tricky as PyMC2 is now fairly old and no longer supported. We anticipate developing code that relies on more user-friendly packages in the future, but for the time being have patience and do your best to work through the environment issues.\n",
    "```\n",
    "PyMC2 requires Python3.8. Therefore, you may want to re-install your original environment and explicitly specify Python 3.8. Once your environment is setup, activate your environment.\n",
    "\n",
    "Next, install the modules required for the emulator.\n",
    "```\n",
    "pip install torch\n",
    "pip install gpytorch\n",
    "```\n",
    "\n",
    "Next, install the modules required for Bayesian inference.\n",
    "```\n",
    "pip install pymc\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "You may try to replace pip install with conda install as conda may help solve dependencies. However, creating this environment can take a long time (> 1 hr), so be patient.\n",
    "```\n",
    "\n",
    "The only way to find out if your package dependencies work is to test it by running the model. Make sure to install PyGEM-Scripts and then [test the model](test_model_target).\n",
    "\n",
    "**If your environment is not set up properly, errors will arise related to missing modules. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.** Getting a correct package installed took the lead developer over a day and unfortunately other users have commented that the directions used by the lead developer have not worked for others due to newer computers or different operating systems.\n",
    "\n",
    "\n",
    "## Install PyGEM-Scripts\n",
    "The scripts that are used to run PyGEM are located in the [PyGEM-Scripts repository](https://github.com/drounce/PyGEM-scripts) on github. To run the model, you can either (i) clone the repository or (ii) fork the repository to develop/add your own scripts. For instructions, follow github’s instructions on [cloning](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) or [forking a repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo). Once the repository is installed on your local machine, you can run the model from this directory.\n",
    "\n",
    "```{note}\n",
    "Be sure that your [directory structure](directory_structure_target) is setup properly before you try running the model!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_model_target)=\n",
    "# Test Model\n",
    "Once the conda environment is [properly installed](install_pygem_target) and you have an understanding of the model components, you are ready to run the model. As described in the [model workflow](model_workflow_target), the model is meant to be run as a sequence of commands from the command line. To test if the model is properly installed and become familiar with the data, sample data for a test run are provided for Khumbu Glacier (RGI60-15.03733) [(download sample data)](https://drive.google.com/file/d/159zS-oGWLHG9nzkFdsf6Uh4-w9lJSt8H/view?usp=sharing). Below are two test workflows for the simple and advanced cases.\n",
    "\n",
    "```{toctree}\n",
    "---\n",
    "caption: Test Case:\n",
    "maxdepth: 2\n",
    "---\n",
    "\n",
    "test_pygem_simple\n",
    "test_pygem_advanced\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "If your environment is not set up properly, errors will arise related to missing modules. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_simple_target)=\n",
    "# Simple Test\n",
    "## Simple calibration\n",
    "Open **pygem_input.py** and check the following (changing as needed):\n",
    "* glac_no = ['15.03733']\n",
    "* ref_startyear = 2000\n",
    "* ref_endyear = 2019\n",
    "* option_calibration = 'HH2015'\n",
    "* option_dynamics = None\n",
    "Then proceed with running the calibration as follows:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "```{note}\n",
    "Command line considerations:\n",
    "<br>Look at arguments in getparser() function for additional command line options, which include options for running in parallel (i.e., we set option_parallels=0 to turn this option off), debugging, etc.\n",
    "```\n",
    "If successful, the script will run without errors and the following will be generated:\n",
    "* ../Output/calibration/15.03733-modelprms_dict.pkl\n",
    "This is a .pkl file that contains the calibration data.\n",
    "\n",
    "## Simple present-day simulation\n",
    "You are now ready to run a simulation. Go back to **pygem_input.py** and check/change:\n",
    "* option_dynamics = 'OGGM'\n",
    "* use_reg_glena = False\n",
    "Then proceed with running the simulation for a reference time period as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0\n",
    "```\n",
    "If successful, the script will run without errors and the following will be generated:\n",
    "* ../Output/simulation/15/ERA5/stats/15.03733_ERA5_HH2015_ba1_1sets_2000_2020_all.nc\n",
    "This is a netcdf file that stores model output from the simulation.\n",
    "\n",
    "## Simple future simulation\n",
    "Now you can try simulating the glacier into the future. Got back to **pygem_input.py** and check/change:\n",
    "* gcm_startyear = 2000\n",
    "* gcm_endyear = 2100\n",
    "Then proceed with running the simulation, while specifying the GCM and scenario through the command line as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0 -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "If successful, the script will run without errors and the following with be generated: \n",
    "* ../Output/simulation/15/CESM2/ssp245/stats/15.03733_CESM2_ssp245_HH2015_ba1_1sets_2000_2020_all.nc\n",
    "\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run PyGEM for your study region!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_advanced_target)=\n",
    "# Advanced Test\n",
    "Here we will go over testing both the emulator and Bayesian inference.\n",
    "\n",
    "## MCMC Calibration\n",
    "Open **pygem_input.py** and check the following (changing as needed):\n",
    "* glac_no = ['15.03733']\n",
    "* ref_startyear = 2000\n",
    "* ref_endyear = 2019\n",
    "* option_calibration = 'emulator'\n",
    "* option_dynamics = None\n",
    "Then proceed with running the calibration:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "```{note}\n",
    "Command line considerations:\n",
    "<br>Look at arguments in getparser() function for additional command line options, which include options for running in parallel (i.e., we set option_parallels=0 to turn this option off), debugging, etc.\n",
    "```\n",
    "If successful, the script will run without errors and the following datasets will be generated:\n",
    "* ../Output/calibration/15.03733-modelprms_dict.pkl\n",
    "* ../emulator/sims/15.03733-100_emulator_sims.csv\n",
    "* ../emulator/models/‘15.03733-emulator-mb_mwea.pth\n",
    "* ../emulator/models/‘15.03733-emulator-mb_mwea_extra.pkl\n",
    "These contain the calibration data, simulations used to create the emulator, and information needed to recreate the emulator.\n",
    "\n",
    "```{note}\n",
    "Normally the next step would be to run this for all glaciers in a region and then determine the prior distributions for the MCMC methods; however, given we're just testing on a single glacier, skip this step and use the default priors from the '../Output/calibration/priors.region.csv'.\n",
    "```\n",
    "\n",
    "Next, run the calibration again using the Bayesian inference. Open the **pygem_input.py** and check/change the following:\n",
    "* option_calibration = 'MCMC'\n",
    "Then proceed with running the calibration:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "If successful, the script will run without errors and no new calibration file will be produced. Why? Because the modelprms_dict.pkl file contains all the data. To quickly check that the MCMC was successful, the model will generate the following:\n",
    "* ../Output/mcmc_success/15/15.03733-mcmc_success.txt\n",
    "\n",
    "```{warning}\n",
    "This (i.e., the run_calibration.py with the emulator and MCMC options) is where errors related to missing modules will arise. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.\n",
    "```\n",
    "\n",
    "## MCMC simulations\n",
    "You are now ready to run a simulation. We'll skip the simulation for the reference period and go directly to running a future simulation. Go back to **pygem_input.py** and check/change:\n",
    "* gcm_startyear = 2000\n",
    "* gcm_endyear = 2100\n",
    "* option_dynamics = 'OGGM'\n",
    "* use_reg_glena = False\n",
    "* sim_iters = 50\n",
    "Then proceed with running the simulation, while specifying the GCM and scenario through the command line as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0 -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "If successful, the script will run without errors and the following with be generated: \n",
    "* ../Output/simulation/15/CESM2/ssp245/stats/15.03733_CESM2_ssp245_MCMC_ba1_1sets_2000_2020_all.nc\n",
    "This is a netcdf file that stores model output from the simulation.\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run PyGEM for your study region!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output \n",
    "The model outputs a variety of data including monthly mass balance and its components (accumulation, melt, refreezing, frontal ablation, glacier runoff), and annual mass, mass below sea level, and area. Results are written as a netcdf file (.nc) for each glacier. If multiple simulations are performed (e.g., for Monte Carlo simulations), then statistics related to the median and median absolute deviation are output for each parameter. In addition to this standard glacier-wide output, binned output is also available, which include the bin’s surface elevation, volume, thickness, and climatic mass balance annually. Additional output can be exported by modifying the **run_simulation.py** script.\n",
    "\n",
    "## Post-processing Data\n",
    "- Add examples of merge and files produced\n",
    "\n",
    "## Analyzing Results\n",
    "- Add examples of figures/plots generated (e.g., mass change and cross sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do list:\n",
    "* Add automatic function/class list!\n",
    "* Add output info in the workflow (like was done for the test\n",
    "* Add simple model script for processing output\n",
    "* Add simple model script for analyzing output with various options\n",
    "* Incorporate Bias Correction info\n",
    "   - May want to highlight the workflow of the simulation script\n",
    "* Incorporate spatial and temporal resolution info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.1 Bias Corrections\n",
    "Bias corrections can be applied to ensure the temperature and precipitation associated with the future climate data is roughly consistent with the reference climate data over the reference time period. The temperature bias corrections follow Huss and Hock (2015) and use an additive factor to ensure the mean monthly temperature and interannual monthly variability are consistent between the reference climate data and the future climate data. There are two options for the precipitation bias correction. Option 2 follows Huss and Hock (2015) and uses a multiplicative factor to ensure the monthly mean precipitation are consistent between the reference climate data and future climate data. In dry regions, for some glaciers the multiplicative values used to adjust the precipitation were found to be unrealistically high; therefore Option 1 modifies the approach of Huss and Hock (2015) to use the interannual monthly variability and quality controls the bias corrected precipitation by replacing any values that exceed the monthly maximum with the monthly average adjusted for potentially wetter years in the future using the normalized annual variation. Marzeion et al. (2020) suggests that Huss and Hock (2015) have updated their approach to also adjust the precipitation bias correction to account for monthly interannual variability as well.\n",
    "\n",
    "Note that these bias corrections significantly impact projections for all glacier evolution models. Future work should thus consider how these bias corrections are implemented. For example, correcting for the 20-year reference period will adjust precipitation even if the precipitation values are off due to a difference in timing of large-scale atmospheric processes (e.g., North Atlantic Oscillations or El Niños). Future work may also want to consider other approaches such as quantile mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial and Temporal Resolution\n",
    "Each glacier is modeled independently. The model is currently set up to use a monthly timestep and elevation bins. We plan to add options to include daily timesteps in the future. The elevation bins can be specified in pre-processing with OGGM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env_wpygem] *",
   "language": "python",
   "name": "conda-env-oggm_env_wpygem-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
