{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\"\"\"\n",
    "Python Glacier Evolution Model \"PyGEM\" V1.0\n",
    "Prepared by David Rounce with support from Regine Hock.\n",
    "This work was funded under the NASA HiMAT project (INSERT PROJECT #).\n",
    "\n",
    "PyGEM is an open source glacier evolution model written in python.  Model\n",
    "details come from Radic et al. (2013), Bliss et al. (2014), and Huss and Hock\n",
    "(2015).\n",
    "\"\"\"\n",
    "###############################################################################\n",
    "# This is the main script that provides the architecture and framework for all\n",
    "# of the model runs. All input data is included in a separate module called\n",
    "# pygem_input.py. It is recommended to not make any changes to this file unless\n",
    "# you are a PyGEM developer and making changes to the model architecture.\n",
    "#\n",
    "#========== IMPORT PACKAGES ==================================================\n",
    "# Various packages are used to provide the proper architecture and framework\n",
    "# for the calculations used in this script. Some packages (e.g., datetime) are\n",
    "# included in order to speed of calculations and simplify code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os # os is used with re to find name matches\n",
    "import re # see os\n",
    "import xarray as xr\n",
    "#========= IMPORT MODEL INPUTS ===============================================\n",
    "from pygem_input import *\n",
    "    # import all data\n",
    "    # pygem_input.py contains all the input data\n",
    "#========== IMPORT FUNCTIONS FROM MODULES ====================================\n",
    "import pygemfxns_modelsetup as modelsetup\n",
    "import pygemfxns_climate as climate\n",
    "import pygemfxns_massbalance as massbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#========== OTHER STEPS ======================================================\n",
    "# Other steps:\n",
    "# Geodetic mass balance file path\n",
    "# ???[Create input script full of option list]???\n",
    "#       - Select regions: (Option 1 - default regions from RGI inventory)\n",
    "#                         (Option 2 - custom regions)\n",
    "#       - Select climate data:\n",
    "#           - climate data source/file name\n",
    "#           - climate data resolution\n",
    "#           - sampling scheme (nearest neighbor, etc.)\n",
    "#       - Model run type: (Option 1 - calibration)\n",
    "#                         (Option 2 - simulation)\n",
    "#\n",
    "\n",
    "#========== LIST OF OUTPUT ===================================================\n",
    "# Create a list of outputs (.csv or .txt files) that the user can choose from\n",
    "# depending on what they are using the model for or want to see:\n",
    "#    1. Time series of all variables for each grid point (x,y,z) of each glacier\n",
    "#       and every time step\n",
    "#       (--> comparing with point balances)\n",
    "#    2. Time series of all variables for elevation bands if spatial\n",
    "#       discretization is elevation bands (x,y,z) of each glacier and every time\n",
    "#       step\n",
    "#       (--> comparing with profiles)\n",
    "#    3. as above but all variables averaged over current single glacier surfaces\n",
    "#       (--> comparing with geodetic mass balances of glaciers)\n",
    "#    4. Time series of all variables averaged over region\n",
    "#       (--> comparison to GRACE)\n",
    "#    5. Time series of seasonal balance for individual glaciers\n",
    "#       (--> comparison to WGMS data)\n",
    "# Also develop output log file, i.e., file that states input parameters,\n",
    "# date of model run, model options selected, and any errors that may have come\n",
    "# up (e.g., precipitation corrected because negative value, etc.)\n",
    "\n",
    "#========== MODEL RUN DETAILS ================================================\n",
    "# The model is run through a series of steps:\n",
    "#   > Step 01: Region/Glaciers Selection\n",
    "#              The user needs to define the region/glaciers that will be used in\n",
    "#              the model run.  The user has the option of choosing the standard\n",
    "#              RGI regions or defining their own.\n",
    "#   > Step 02: Model Time Frame\n",
    "#              The user should consider the time step and duration of the model\n",
    "#              run along with any calibration product and/or model spinup that\n",
    "#              may be included as well.\n",
    "#   > Step 03: Climate Data\n",
    "#              The user has the option to choose the type of climate data being\n",
    "#              used in the model run, and how that data will be downscaled to\n",
    "#              the glacier and bins.\n",
    "#   > Step 04: Glacier Evolution\n",
    "#              The heart of the model is the glacier evolution, which includes\n",
    "#              calculating the specific mass balance, the surface type, and any\n",
    "#              changes to the size of the glacier (glacier dynamics). The user\n",
    "#              has many options for how this aspect of the model is run.\n",
    "#   > Others: model output? model input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This study is only focusing on glaciers ['03473', '03733'] in region [15].\n",
      "The 'select_rgi_glaciers' function has finished.\n"
     ]
    }
   ],
   "source": [
    "#----- STEP ONE: MODEL REGION/GLACIERS ---------------------------------------\n",
    "# Step one involves the selection of the regions and glaciers used in the model.\n",
    "# Regions/glacier included in the model run will be defined using the Randolph\n",
    "#   Glacier inventory.  For more information, see:\n",
    "#     https://www.glims.org/RGI/ (RGI Consortium, 2017)\n",
    "# In step one, the model will:\n",
    "#   > select glaciers included in model run\n",
    "\n",
    "# Select glaciers that are included in the model run\n",
    "# Glacier Selection Options:\n",
    "#   > 1 (default) - enter numbers associated with RGI V6.0 and select\n",
    "#                   glaciers accordingly\n",
    "#   > 2 - glaciers/regions selected via shapefile\n",
    "#   > 3 - glaciers/regions selected via new table (other inventory)\n",
    "#\n",
    "if option_glacier_selection == 1:\n",
    "    main_glac_rgi = modelsetup.selectglaciersrgitable()\n",
    "elif option_glacier_selection == 2:\n",
    "    # OPTION 2: CUSTOMIZE REGIONS USING A SHAPEFILE that specifies the\n",
    "    #           various regions according to the RGI IDs, i.e., add an\n",
    "    #           additional column to the RGI table.\n",
    "    # ??? [INSERT CODE FOR IMPORTING A SHAPEFILE] ???\n",
    "    #   (1) import shapefile with custom boundaries, (2) grab the RGIIDs\n",
    "    #   of glaciers that are in these boundaries, (3) perform calibration\n",
    "    #   using these alternative boundaries that may (or may not) be more\n",
    "    #   representative of regional processes/climate\n",
    "    #   Note: this is really only important for calibration purposes and\n",
    "    #         post-processing when you want to show results over specific\n",
    "    #         regions.\n",
    "    # Development Note: if create another method for selecting glaciers,\n",
    "    #                   make sure that update way to select glacier\n",
    "    #                   hypsometry as well.\n",
    "    print('\\n\\tMODEL ERROR (selectglaciersrgi): this option to use'\n",
    "          '\\n\\tshapefiles to select glaciers has not been coded yet.'\n",
    "          '\\n\\tPlease choose an option that exists. Exiting model run.\\n')\n",
    "    exit()\n",
    "else:\n",
    "    # Should add options to make regions consistent with Brun et al. (2017),\n",
    "    # which used ASTER DEMs to get mass balance of 92% of the HMA glaciers.\n",
    "    print('\\n\\tModel Error (selectglaciersrgi): please choose an option'\n",
    "          '\\n\\tthat exists for selecting glaciers. Exiting model run.\\n')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             RGI-ID  Cont_range  25  35  45  55  65  75  85  95  ...   8725  \\\n",
      "0  RGIv6.0.15-00001           1 -99 -99 -99 -99 -99 -99 -99 -99  ...  -99.0   \n",
      "1  RGIv6.0.15-00002           1 -99 -99 -99 -99 -99 -99 -99 -99  ...  -99.0   \n",
      "2  RGIv6.0.15-00003           1 -99 -99 -99 -99 -99 -99 -99 -99  ...  -99.0   \n",
      "3  RGIv6.0.15-00004           1 -99 -99 -99 -99 -99 -99 -99 -99  ...  -99.0   \n",
      "4  RGIv6.0.15-00005           0 -99 -99 -99 -99 -99 -99 -99 -99  ...  -99.0   \n",
      "\n",
      "   8735  8745  8755  8765  8775  8785  8795  8805  8815  \n",
      "0   -99 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0  \n",
      "1   -99 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0  \n",
      "2   -99 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0  \n",
      "3   -99 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0  \n",
      "4   -99 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0 -99.0  \n",
      "\n",
      "[5 rows x 882 columns]\n"
     ]
    }
   ],
   "source": [
    "#----- STEP TWO: ADDITIONAL MODEL SETUP --------------------------------------\n",
    "# Step two runs more functions related to the model setup. This section has been\n",
    "#   separated from the selection of the model region/glaciers in order to\n",
    "#   keep the input organized and easy to read.\n",
    "# In step two, the model will:\n",
    "#   > select glacier hypsometry\n",
    "#   > define the model time frame\n",
    "#   > define the initial surface type\n",
    "\n",
    "# Glacier hypsometry\n",
    "# main_glac_hyps = modelsetup.hypsometryglaciers(main_glac_rgi)\n",
    "    # Note: need to adjust this hypsometry into separate functions such that it\n",
    "    #       is easier to follow.\n",
    "# AUTOMATE THIS TO LOAD THEM IN INSTEAD OF CHOOSING THEM\n",
    "# main_glac_hyps = pd.read_csv(hyps_filepath + 'RGI_13_area_test20170905.csv')\n",
    "ds = pd.read_csv(hyps_filepath + 'bands_10m_DRR/area_15_Huss_SouthAsiaEast_10m.csv')\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                RGI-ID Cont_range   25   35   45   55   65   75   85   95  \\\n",
      "3472  RGIv6.0.15-03473          1  -99  -99  -99  -99  -99  -99  -99  -99   \n",
      "3732  RGIv6.0.15-03733          1  -99  -99  -99  -99  -99  -99  -99  -99   \n",
      "\n",
      "     ...  8725 8735 8745 8755 8765 8775 8785 8795 8805 8815  \n",
      "3472 ...   -99  -99  -99  -99  -99  -99  -99  -99  -99  -99  \n",
      "3732 ...   -99  -99  -99  -99  -99  -99  -99  -99  -99  -99  \n",
      "\n",
      "[2 rows x 882 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select glaciers based on 01Index value from main_glac_rgi table\n",
    "glac_hyps_table = pd.DataFrame()\n",
    "for glacier in range(len(main_glac_rgi)):\n",
    "    if glac_hyps_table.empty:\n",
    "        glac_hyps_table = ds.loc[main_glac_rgi.loc[glacier,'O1Index']]\n",
    "    else:\n",
    "        glac_hyps_table = pd.concat([glac_hyps_table, ds.loc[main_glac_rgi.loc[glacier,'O1Index']]], axis=1)\n",
    "glac_hyps_table = glac_hyps_table.transpose()\n",
    "print(glac_hyps_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         25   35   45   55   65   75   85   95  105  115 ...  8725 8735 8745  \\\n",
      "GlacNo                                                   ...                   \n",
      "0       -99  -99  -99  -99  -99  -99  -99  -99  -99  -99 ...   -99  -99  -99   \n",
      "1       -99  -99  -99  -99  -99  -99  -99  -99  -99  -99 ...   -99  -99  -99   \n",
      "\n",
      "       8755 8765 8775 8785 8795 8805 8815  \n",
      "GlacNo                                     \n",
      "0       -99  -99  -99  -99  -99  -99  -99  \n",
      "1       -99  -99  -99  -99  -99  -99  -99  \n",
      "\n",
      "[2 rows x 880 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean up table and re-index\n",
    "# Reset index to be GlacNo\n",
    "glac_hyps_table.reset_index(drop=True, inplace=True)\n",
    "glac_hyps_table.index.name = indexname\n",
    "glac_hyps_table.drop(['RGI-ID','Cont_range'], axis=1, inplace=True)\n",
    "print(glac_hyps_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        O1Index           RGIId     CenLon     CenLat  O1Region  O2Region  \\\n",
      "GlacNo                                                                      \n",
      "0          3472  RGI60-15.03473  86.715912  28.089468        15         2   \n",
      "1          3732  RGI60-15.03733  86.903244  27.974716        15         2   \n",
      "\n",
      "          Area  Zmin  Zmax  Zmed  Slope  Aspect   Lmax     Volume  \n",
      "GlacNo                                                             \n",
      "0       61.054  4702  8181  5815   16.5     180  18285  84.527037  \n",
      "1       19.097  4926  7870  5568   17.5     262  15396   0.533249   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Glacier initial ice thickness\n",
    "# AUTOMATE THIS TO LOAD THEM IN INSTEAD OF CHOOSING THEM\n",
    "main_glac_icethickness = pd.read_csv(hyps_filepath +\n",
    "                                     'RGI_13_thickness_test20170905.csv')\n",
    "# ADD OPTION FOR VOLUME-AREA SCALING\n",
    "\n",
    "# Glacier total initial volume\n",
    "main_glac_rgi['Volume'] = (\n",
    "    (main_glac_hyps * main_glac_icethickness/1000).sum(axis=1))\n",
    "    # volume [km3] = area[km2] * thickness[m] * (1 [km] / 1000 [m])\n",
    "\n",
    "print(main_glac_rgi.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'datesmodelrun' function has finished.\n",
      "               date  year  month  daysinmonth\n",
      "timestep                                     \n",
      "0        2000-01-01  2000      1           31\n",
      "1        2000-02-01  2000      2           29\n",
      "2        2000-03-01  2000      3           31\n",
      "3        2000-04-01  2000      4           30\n",
      "4        2000-05-01  2000      5           31\n"
     ]
    }
   ],
   "source": [
    "# Model time frame\n",
    "#   Set up table of dates. These dates are used as column headers for many other\n",
    "#   variables in the model run, so it's important to be an initial step.\n",
    "dates_table, start_date, end_date = modelsetup.datesmodelrun(option_leapyear)\n",
    "print(dates_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date  year  month  daysinmonth  year_water\n",
      "timestep                                                 \n",
      "0        2000-01-01  2000      1           31        2000\n",
      "1        2000-02-01  2000      2           29        2000\n",
      "2        2000-03-01  2000      3           31        2000\n",
      "3        2000-04-01  2000      4           30        2000\n",
      "4        2000-05-01  2000      5           31        2000\n",
      "5        2000-06-01  2000      6           30        2000\n",
      "6        2000-07-01  2000      7           31        2000\n",
      "7        2000-08-01  2000      8           31        2000\n",
      "8        2000-09-01  2000      9           30        2000\n",
      "9        2000-10-01  2000     10           31        2001\n",
      "10       2000-11-01  2000     11           30        2001\n",
      "11       2000-12-01  2000     12           31        2001\n",
      "12       2001-01-01  2001      1           31        2001\n",
      "13       2001-02-01  2001      2           28        2001\n",
      "14       2001-03-01  2001      3           31        2001\n"
     ]
    }
   ],
   "source": [
    "# PUT IN OPTION TO USE LEAP YEAR AND WATER YEAR\n",
    "\n",
    "# Water year for northern hemisphere using USGS definition (October 1 - September 30th),\n",
    "# e.g., water year for 2000 is from October 1, 1999 - September 30, 2000\n",
    "dates_table['year_water'] = dates_table['year']\n",
    "for step in range(len(dates_table)):\n",
    "    if dates_table.loc[step, 'month'] >= 10:\n",
    "        dates_table.loc[step, 'year_water'] = dates_table.loc[step, 'year'] + 1\n",
    "\n",
    "# Develops note: MAKE ADJUSTMENTS FOR LATITUDE THRESHOLDS, ETC. LIKE VALENTINA DID IF DESIRED\n",
    "        \n",
    "print(dates_table.head(15))\n",
    "\n",
    "# Valentina's code:\n",
    "# % m1 is the starting month of the mass balance year (start of winter). It depends on the latitude of the glacier.\n",
    "# % m2 = 13-m1; and is used to index Prec and Temp\n",
    "# param.latitudethresh = 75;  %different definition of start of winter/summer below and above this latitude\n",
    "# if (lat > param.latitudethresh)\n",
    "#     m1=9; m2=4;\n",
    "# elseif (lat >= 0 && lat <= param.latitudethresh)\n",
    "#     m1=10; m2=3;\n",
    "# elseif (lat < -param.latitudethresh)\n",
    "#     m1=3; m2=10;\n",
    "# else %-75 < lat < 0\n",
    "#     m1=4; m2=9;\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'initialsurfacetype' function has finished.\n"
     ]
    }
   ],
   "source": [
    "# Initial surface type\n",
    "main_glac_surftypeinit = modelsetup.surfacetypeglacinitial(\n",
    "                                                option_surfacetype_initial,\n",
    "                                                option_surfacetype_firn,\n",
    "                                                option_surfacetype_debris,\n",
    "                                                main_glac_rgi,\n",
    "                                                main_glac_hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   # glacnum           x          y    z_med    z_p16    z_p84  mb_mwea  \\\n",
      "0   14.19942  -927804.01  -35168.38  7496.07  7415.89  7650.54     1.02   \n",
      "1   14.23897 -1157128.32  106023.79  7408.39  7353.91  7467.04     1.74   \n",
      "2   15.05141   -44297.11 -837269.98  7349.13  7026.94  7473.72     0.64   \n",
      "3   14.19948  -929689.48  -36435.04  7249.72  6932.15  7544.95     0.53   \n",
      "4   14.23883 -1157892.34  106248.27  7193.10  7071.63  7298.66     1.12   \n",
      "\n",
      "   area_km2       t1      t2     dt  \n",
      "0      2.82  2000.11  2015.0  14.89  \n",
      "1      0.10  2000.11  2015.0  14.89  \n",
      "2      1.57  2000.11  2015.0  14.89  \n",
      "3      2.29  2000.11  2015.0  14.89  \n",
      "4      0.38  2000.11  2015.0  14.89  \n"
     ]
    }
   ],
   "source": [
    "# Mass balance estimates from High-res DEMs\n",
    "mb_filepath = '../DEMs/hma_mb_20170717_1846.csv'\n",
    "# mb_filepath = os.path.dirname(__file__) + '/../DEMs/hma_mb_20170717_1846.csv'\n",
    "main_glac_mb_raw = pd.read_csv(mb_filepath)\n",
    "print(main_glac_mb_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----- STEP THREE: CLIMATE DATA ----------------------------------------------\n",
    "# Step three imports the climate data that will be used in the model run.\n",
    "# Provide options for the selection and downscaling of the data\n",
    "#    - default: nearest neighbor\n",
    "#    - alternatives: weighted methods\n",
    "#      (note: prior to any weighting, lapse rates/biases need to be applied)\n",
    "# Important to consider the following:\n",
    "#    - time period of the calibration data or model run\n",
    "#    - type of model (DDF, EBM, etc.) will dictate meteorological data needed\n",
    "#   Datasets:\n",
    "#     Past: Default: ERA reanslysis?\n",
    "#           Alternatives: COAWST (S.Nichols), NCEP/NCAR(?), others?\n",
    "#                         automatic weather stations\n",
    "#     Future: Default: GCMs (see glacierMIP project emails to download data)\n",
    "#             Alternatives: COAWST (S.Nichols), others?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'importGCMvarnearestneighbor' fxn for 'tas' has finished.\n",
      "The 'importGCMvarnearestneighbor' fxn for 'pr' has finished.\n",
      "The 'importGCMfxnearestneighbor' fxn for 'orog' has finished.\n",
      "          2000-01   2000-02   2000-03   2000-04   2000-05    2000-06  \\\n",
      "GlacNo                                                                 \n",
      "0      -10.502808 -7.882294 -0.942657  6.147675  11.90567  11.852539   \n",
      "1       -9.147339 -7.106903 -0.382111  6.294159  10.59317  11.092773   \n",
      "\n",
      "          2000-07    2000-08   2000-09   2000-10    ...      2100-03  \\\n",
      "GlacNo                                              ...                \n",
      "0       16.923706  15.013214  7.489838  3.064972    ...     3.170441   \n",
      "1       16.359253  15.079620  7.021088  3.662628    ...     2.879425   \n",
      "\n",
      "         2100-04    2100-05    2100-06    2100-07    2100-08    2100-09  \\\n",
      "GlacNo                                                                    \n",
      "0       8.817596  15.482788  18.429291  22.631256  22.814758  18.546356   \n",
      "1       8.438690  14.510132  17.603119  21.840240  22.763977  18.519012   \n",
      "\n",
      "         2100-10   2100-11   2100-12  \n",
      "GlacNo                                \n",
      "0       9.294525  3.202057 -3.902496  \n",
      "1       9.909760  3.569244 -2.726715  \n",
      "\n",
      "[2 rows x 1212 columns]\n"
     ]
    }
   ],
   "source": [
    "# In step three, the model will:\n",
    "#   > import meteorological data\n",
    "#   > select meteorological data for each glacier based on specified option\n",
    "#       default: nearest neighbor\n",
    "if option_gcm_downscale == 1:\n",
    "    # OPTION 1 (default): NEAREST NEIGHBOR\n",
    "    # Thoughts on 2017/08/21:\n",
    "    #   > Pre-processing functions should be coded and added after the initial\n",
    "    #     import such that the initial values can be printed if necessary.\n",
    "    #   > Data imported here is monthly, i.e., it is 1 value per month. If the\n",
    "    #     data is going to be subsampled to a daily resolution in order to\n",
    "    #     estimate melt in areas with low monthly mean temperature as is done in\n",
    "    #     Huss and Hock (2015), then those calculations should be performed in\n",
    "    #     the ablation section.\n",
    "    gcm_glac_temp = climate.importGCMvarnearestneighbor(gcm_temp_varname,\n",
    "                                                        main_glac_rgi,\n",
    "                                                        dates_table)\n",
    "        # gcm nearest neighbor time series for each glacier with GlacNo index\n",
    "        # rows = # of glaciers, cols = length of time series\n",
    "    gcm_glac_prec = climate.importGCMvarnearestneighbor(gcm_prec_varname,\n",
    "                                                        main_glac_rgi,\n",
    "                                                        dates_table)\n",
    "        # gcm nearest neighbor time series for each glacier with GlacNo index\n",
    "        # rows = # of glaciers, cols = length of time series\n",
    "    gcm_glac_elev = climate.importGCMfxnearestneighbor(gcm_elev_varname,\n",
    "                                                       main_glac_rgi)\n",
    "        # gcm nearest neighbor surface altitude for each glacier with GlacNo\n",
    "        # index, rows = # of glaciers, cols = 1 (Series)\n",
    "else:\n",
    "    print('\\n\\tModel Error: please choose an option that exists for'\n",
    "          '\\n\\tdownscaling climate data. Exiting model run now.\\n')\n",
    "    exit() # if you have an error, exit the model run\n",
    "\n",
    "print(gcm_glac_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'tas' (time: 2772, lat: 96, lon: 192)>\n",
      "dask.array<open_dataset-b3f237a6ce742e793cb70511c7663e2btas, shape=(2772, 96, 192), dtype=float64, chunksize=(2772, 96, 192)>\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1870-01-15T12:00:00 1870-02-15 ...\n",
      "  * lat      (lat) float64 -88.57 -86.72 -84.86 -83.0 -81.13 -79.27 -77.41 ...\n",
      "  * lon      (lon) float64 0.0 1.875 3.75 5.625 7.5 9.375 11.25 13.12 15.0 ...\n",
      "Attributes:\n",
      "    units:          K\n",
      "    long_name:      Near-Surface Air Temperature\n",
      "    standard_name:  air_temperature\n"
     ]
    }
   ],
   "source": [
    "# use xarray to select climate data\n",
    "# xarray is built to emulate the netcdf framework, is built on top of pandas,\n",
    "# and is lazy - it won't load in the data until it is used.\n",
    "# Therefore, instead of importing everything and then selecting the data as needed,\n",
    "# xarray will only import the data that is being used.  It should greatly speed up \n",
    "# computational time.\n",
    "\n",
    "variablename = 'tas'\n",
    "# Import netcdf file\n",
    "filefull = gcm_filepath_var + variablename + gcm_filename_var\n",
    "data = xr.open_mfdataset(filefull)\n",
    "# mfdataset uses dask to speed up processing\n",
    "print(data['tas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1870-01-15T12:00:00 1870-02-15 ...\n",
       "  * lat      (lat) float64 -88.57 -86.72 -84.86 -83.0 -81.13 -79.27 -77.41 ...\n",
       "  * lon      (lon) float64 0.0 1.875 3.75 5.625 7.5 9.375 11.25 13.12 15.0 ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 96, lon: 192, time: 1)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2000-01-15T12:00:00\n",
       "  * lat      (lat) float64 -88.57 -86.72 -84.86 -83.0 -81.13 -79.27 -77.41 ...\n",
       "  * lon      (lon) float64 0.0 1.875 3.75 5.625 7.5 9.375 11.25 13.12 15.0 ...\n",
       "Data variables:\n",
       "    tas      (time, lat, lon) float64 240.1 240.1 240.0 240.1 240.0 240.0 ...\n",
       "Attributes:\n",
       "    source_model:        MPI-ESM-LR\n",
       "    source_ensemble:     r1i1p1\n",
       "    source_experiment:   historical,rcp85\n",
       "    source_institution:  Max Planck Institute for Meteorology\n",
       "    source_contact:      cmip5-mpi-esm@dkrz.de\n",
       "    source_files:        tas_Amon_MPI-ESM-LR_historical_r1i1p1_185001-200512....\n",
       "    source_md5:          14ea33cdaec9d54cae0f986255b4b21b,82e3ca65b6338ff918f...\n",
       "    freq:                monthly\n",
       "    interpolation_grid:  native\n",
       "    contact:             cmip5-archive@env.ethz.ch\n",
       "    modifications:       nothing"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sel(time='2000-01-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 96, time: 2772)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1870-01-15T12:00:00 1870-02-15 ...\n",
       "  * lat      (lat) float64 -88.57 -86.72 -84.86 -83.0 -81.13 -79.27 -77.41 ...\n",
       "    lon      float64 180.0\n",
       "Data variables:\n",
       "    tas      (time, lat) float64 237.3 245.1 254.0 258.2 257.8 258.1 264.8 ...\n",
       "Attributes:\n",
       "    source_model:        MPI-ESM-LR\n",
       "    source_ensemble:     r1i1p1\n",
       "    source_experiment:   historical,rcp85\n",
       "    source_institution:  Max Planck Institute for Meteorology\n",
       "    source_contact:      cmip5-mpi-esm@dkrz.de\n",
       "    source_files:        tas_Amon_MPI-ESM-LR_historical_r1i1p1_185001-200512....\n",
       "    source_md5:          14ea33cdaec9d54cae0f986255b4b21b,82e3ca65b6338ff918f...\n",
       "    freq:                monthly\n",
       "    interpolation_grid:  native\n",
       "    contact:             cmip5-archive@env.ethz.ch\n",
       "    modifications:       nothing"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sel(lon=180.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'tas' (time: 2772, lat: 96)>\n",
       "dask.array<getitem, shape=(2772, 96), dtype=float64, chunksize=(2772, 96)>\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1870-01-15T12:00:00 1870-02-15 ...\n",
       "  * lat      (lat) float64 -88.57 -86.72 -84.86 -83.0 -81.13 -79.27 -77.41 ...\n",
       "    lon      float64 180.0\n",
       "Attributes:\n",
       "    units:          K\n",
       "    long_name:      Near-Surface Air Temperature\n",
       "    standard_name:  air_temperature"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tas'].sel(lon=180.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tas'].sel(time='2015lon=180.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
